{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a83ca33-c4af-44d0-bfc1-2e77018dc26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from sklearn.model_selection import KFold, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4778aecf-73cb-4404-8cdc-01041192801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classification dataset\n",
    "dft = pd.read_csv(r\"C:\\Users\\basde\\Documents\\GitHub\\Code-and-examples\\Projects\\Binary Classification with a Bank Dataset\\train.csv\")\n",
    "dfo = pd.read_csv(r\"C:\\Users\\basde\\Documents\\GitHub\\Code-and-examples\\Projects\\Binary Classification with a Bank Dataset\\bank-full.csv\", delimiter=';')\n",
    "dfo['y'] = dfo['y'].map({'no' : 0, 'yes': 1})\n",
    "# df = pd.concat([dft, dfo])\n",
    "y = dfo['y']\n",
    "dfo = dfo.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80419a82-90ce-450f-ab82-5505c7767502",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo['default'] = pd.get_dummies(dfo['default'], drop_first=True, dtype=int)\n",
    "dfo['housing'] = pd.get_dummies(dfo['housing'], drop_first=True, dtype=int)\n",
    "dfo['loan'] = pd.get_dummies(dfo['loan'], drop_first=True, dtype=int)\n",
    "dfo['contact'] = dfo['contact'].map({'telephone': 'cellular', 'unknown' : 'unknown', 'telephone': 'telephone'})\n",
    "dfo['contact'] = pd.get_dummies(dfo['contact'], drop_first=True, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23f07bcd-ec39-4310-b091-7229ed2115e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32a57e6f-9253-45da-9061-3aff95b21f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfo.select_dtypes(include=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29e4e136-5974-4ba6-985c-335623f2133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Specify the feature to apply transformations on\n",
    "# You can change 'Age' to any other numerical column name from your dataframe\n",
    "feature_to_transform = 'duration'\n",
    "\n",
    "# b. Define the classification models to evaluate\n",
    "models = {\n",
    "    \"LightGBM\": lgb.LGBMClassifier(random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(random_state=42, verbose=0)\n",
    "}\n",
    "\n",
    "# c. Define the transformation pipelines to test on the specified feature\n",
    "# The ColumnTransformer applies the specified pipeline to the 'feature_to_transform'\n",
    "# and leaves the other features untouched (remainder='passthrough').\n",
    "transformation_pipelines = {\n",
    "    'Log Transformation': ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('transformer', Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('log', FunctionTransformer(np.log1p))\n",
    "            ]), [feature_to_transform])\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    ),\n",
    "    'Square Root Transformation': ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('transformer', Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('sqrt', FunctionTransformer(np.sqrt))\n",
    "            ]), [feature_to_transform])\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    ),\n",
    "    'Winsorization (0-95%)': ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('transformer', Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('winsorizer', Winsorizer(capping_method='quantiles', tail='right', fold=0.05))\n",
    "            ]), [feature_to_transform])\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "}\n",
    "\n",
    "# d. Define the classification scoring metrics\n",
    "scoring_metrics = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_score': 'f1_weighted',\n",
    "    'precision': 'precision_weighted',\n",
    "    'recall': 'recall_weighted'\n",
    "}\n",
    "\n",
    "# e. Define the cross-validation strategy\n",
    "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c293cf4-e09f-4180-b5a0-cd919777ce60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating Model: LightGBM ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 698\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 699\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 697\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 697\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 699\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- feature dropped: LightGBM ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 953\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 954\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 952\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 952\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 954\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- imputation only: LightGBM ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 953\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 954\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 952\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 952\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 954\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- tranformation: Log Transformation ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 953\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 954\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 952\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 952\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 954\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- tranformation: Square Root Transformation ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 953\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 954\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 952\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 952\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 954\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- tranformation: Winsorization (0-95%) ---\n",
      "--- Evaluating Model: CatBoost ---\n",
      "--- feature dropped: CatBoost ---\n",
      "--- imputation only: CatBoost ---\n",
      "--- tranformation: Log Transformation ---\n",
      "--- tranformation: Square Root Transformation ---\n",
      "--- tranformation: Winsorization (0-95%) ---\n"
     ]
    }
   ],
   "source": [
    "# This DataFrame will hold all results for final comparison\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "# --- Main Loop ---\n",
    "for model_name, model in models.items():\n",
    "    print(f\"--- Evaluating Model: {model_name} ---\")\n",
    "    model_results = {}\n",
    "\n",
    "    # a. \"Feature Dropped\" Evaluation\n",
    "    # Dynamically drops the feature specified in cell 3\n",
    "    X_dropped = X.drop(columns=[feature_to_transform])\n",
    "    feature_dropped_scores = cross_validate(\n",
    "        model, X_dropped, y, cv=cv_strategy,\n",
    "        scoring=scoring_metrics, return_train_score=True\n",
    "    )\n",
    "    model_results['Feature Dropped'] = {\n",
    "        'Train F1-Score': feature_dropped_scores['train_f1_score'].mean(),\n",
    "        'CV F1-Score': feature_dropped_scores['test_f1_score'].mean(),\n",
    "        'CV Accuracy': feature_dropped_scores['test_accuracy'].mean()\n",
    "    }\n",
    "    print(f\"--- feature dropped: {model_name} ---\")\n",
    "    # b. \"Imputation Only\" Baseline Evaluation\n",
    "    # Applies imputation only to the specified feature, others are passed through\n",
    "    baseline_preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('imputer', SimpleImputer(strategy='median'), [feature_to_transform])\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    baseline_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', baseline_preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    baseline_scores = cross_validate(\n",
    "        baseline_pipeline, X, y, cv=cv_strategy,\n",
    "        scoring=scoring_metrics, return_train_score=True\n",
    "    )\n",
    "    model_results['Baseline (Imputation Only)'] = {\n",
    "        'Train F1-Score': baseline_scores['train_f1_score'].mean(),\n",
    "        'CV F1-Score': baseline_scores['test_f1_score'].mean(),\n",
    "        'CV Accuracy': baseline_scores['test_accuracy'].mean()\n",
    "    }\n",
    "    print(f\"--- imputation only: {model_name} ---\")\n",
    "    # c. Transformation Pipelines Evaluation\n",
    "    # Iterates through the ColumnTransformer pipelines defined in cell 3\n",
    "    for tech_name, preprocessor in transformation_pipelines.items():\n",
    "        full_pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        scores = cross_validate(\n",
    "            full_pipeline, X, y, cv=cv_strategy,\n",
    "            scoring=scoring_metrics, return_train_score=True\n",
    "        )\n",
    "        model_results[tech_name] = {\n",
    "            'Train F1-Score': scores['train_f1_score'].mean(),\n",
    "            'CV F1-Score': scores['test_f1_score'].mean(),\n",
    "            'CV Accuracy': scores['test_accuracy'].mean()\n",
    "        }\n",
    "        print(f\"--- tranformation: {tech_name} ---\")\n",
    "    # d. Consolidate and store results\n",
    "    temp_df = pd.DataFrame.from_dict(model_results, orient='index')\n",
    "    temp_df['Model'] = model_name\n",
    "    all_results = pd.concat([all_results, temp_df])\n",
    "\n",
    "# e. Final processing for the results table\n",
    "all_results.reset_index(inplace=True)\n",
    "all_results.rename(columns={'index': 'Preprocessing Technique'}, inplace=True)\n",
    "all_results['Generalization'] = all_results['CV F1-Score'] / all_results['Train F1-Score']\n",
    "all_results = all_results.sort_values(by='CV F1-Score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "488e7202-c308-46ad-8035-3a282447c830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing Technique</th>\n",
       "      <th>CV F1-Score</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>Train F1-Score</th>\n",
       "      <th>Generalization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Baseline (Imputation Only)</td>\n",
       "      <td>0.891245</td>\n",
       "      <td>0.900246</td>\n",
       "      <td>0.913464</td>\n",
       "      <td>0.975676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Log Transformation</td>\n",
       "      <td>0.891245</td>\n",
       "      <td>0.900246</td>\n",
       "      <td>0.913464</td>\n",
       "      <td>0.975676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Square Root Transformation</td>\n",
       "      <td>0.891245</td>\n",
       "      <td>0.900246</td>\n",
       "      <td>0.913464</td>\n",
       "      <td>0.975676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Winsorization (0-95%)</td>\n",
       "      <td>0.890039</td>\n",
       "      <td>0.899383</td>\n",
       "      <td>0.911915</td>\n",
       "      <td>0.976010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>Square Root Transformation</td>\n",
       "      <td>0.889514</td>\n",
       "      <td>0.899449</td>\n",
       "      <td>0.924754</td>\n",
       "      <td>0.961893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>Baseline (Imputation Only)</td>\n",
       "      <td>0.889514</td>\n",
       "      <td>0.899449</td>\n",
       "      <td>0.924754</td>\n",
       "      <td>0.961893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>Log Transformation</td>\n",
       "      <td>0.889514</td>\n",
       "      <td>0.899449</td>\n",
       "      <td>0.924754</td>\n",
       "      <td>0.961893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>Winsorization (0-95%)</td>\n",
       "      <td>0.888676</td>\n",
       "      <td>0.898432</td>\n",
       "      <td>0.923300</td>\n",
       "      <td>0.962500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Feature Dropped</td>\n",
       "      <td>0.858809</td>\n",
       "      <td>0.888479</td>\n",
       "      <td>0.874360</td>\n",
       "      <td>0.982215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>Feature Dropped</td>\n",
       "      <td>0.858723</td>\n",
       "      <td>0.887550</td>\n",
       "      <td>0.884103</td>\n",
       "      <td>0.971293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model     Preprocessing Technique  CV F1-Score  CV Accuracy  \\\n",
       "1  LightGBM  Baseline (Imputation Only)     0.891245     0.900246   \n",
       "2  LightGBM          Log Transformation     0.891245     0.900246   \n",
       "3  LightGBM  Square Root Transformation     0.891245     0.900246   \n",
       "4  LightGBM       Winsorization (0-95%)     0.890039     0.899383   \n",
       "8  CatBoost  Square Root Transformation     0.889514     0.899449   \n",
       "6  CatBoost  Baseline (Imputation Only)     0.889514     0.899449   \n",
       "7  CatBoost          Log Transformation     0.889514     0.899449   \n",
       "9  CatBoost       Winsorization (0-95%)     0.888676     0.898432   \n",
       "0  LightGBM             Feature Dropped     0.858809     0.888479   \n",
       "5  CatBoost             Feature Dropped     0.858723     0.887550   \n",
       "\n",
       "   Train F1-Score  Generalization  \n",
       "1        0.913464        0.975676  \n",
       "2        0.913464        0.975676  \n",
       "3        0.913464        0.975676  \n",
       "4        0.911915        0.976010  \n",
       "8        0.924754        0.961893  \n",
       "6        0.924754        0.961893  \n",
       "7        0.924754        0.961893  \n",
       "9        0.923300        0.962500  \n",
       "0        0.874360        0.982215  \n",
       "5        0.884103        0.971293  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorder columns for a more logical presentation\n",
    "final_columns_order = [\n",
    "    'Model',\n",
    "    'Preprocessing Technique',\n",
    "    'CV F1-Score',\n",
    "    'CV Accuracy',\n",
    "    'Train F1-Score',\n",
    "    'Generalization'\n",
    "]\n",
    "all_results = all_results[final_columns_order]\n",
    "\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be208fa-ad43-40a2-9f48-6a245707584d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
