{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52805e1b-a56f-4607-ab83-dfed83e59ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09e0f355-fbad-4367-b1c8-963b691f47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"C:\\Users\\basde\\OneDrive\\Documenten\\GitHub\\Titanic\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6775bfdf-1499-46ac-926f-f19e94c29862",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Deck'] = train['Cabin'].astype(str).str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48b84fc0-1030-4787-94f2-486d46ca87a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deck\n",
       "n    687\n",
       "C     59\n",
       "B     47\n",
       "D     33\n",
       "E     32\n",
       "A     15\n",
       "F     13\n",
       "G      4\n",
       "T      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Deck'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a845ab69-3da0-49ec-85d8-2a9517008eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "996f86fd-a093-4bc7-b829-152a07fd83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['Age','Pclass','Fare']]\n",
    "y = train['Deck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62df52f-5d46-445b-8fa5-4797ed96463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import KFold, ParameterGrid\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# --- 1. Create a Realistic Sample Dataset ---\n",
    "# We need X, an intermediate target with missing values, and a final target.\n",
    "X_full, y_final = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=25, random_state=42)\n",
    "X_full = pd.DataFrame(X_full, columns=[f'feature_{i}' for i in range(20)])\n",
    "\n",
    "# Create the intermediate variable, making it related to some features and the final target\n",
    "y_intermediate = (0.5 * X_full['feature_2'] + 0.3 * X_full['feature_5'] + 0.2 * y_final + np.random.normal(0, 5, 1000))\n",
    "y_intermediate = pd.Series(y_intermediate, name='intermediate_target')\n",
    "y_final = pd.Series(y_final, name='final_target')\n",
    "\n",
    "# Introduce 80% missing values into the INTERMEDIATE target\n",
    "y_intermediate.loc[y_intermediate.sample(frac=0.8, random_state=42).index] = np.nan\n",
    "\n",
    "# Define which columns are \"correlated\" and will be used for imputation\n",
    "correlated_features = ['feature_2', 'feature_5', 'feature_8', 'feature_10']\n",
    "X_corr = X_full[correlated_features]\n",
    "\n",
    "print(f\"Full feature set shape: {X_full.shape}\")\n",
    "print(f\"Correlated feature set shape: {X_corr.shape}\")\n",
    "print(f\"Intermediate targets missing: {y_intermediate.isna().sum()}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 2. Define Models and Hyperparameter Grid ---\n",
    "# The model for the final prediction\n",
    "main_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "# A simple imputer for the correlated features (in case they also have missing values)\n",
    "feature_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Hyperparameters TO TUNE for the INTERMEDIATE TARGET IMPUTATION model\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 7, 15],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# --- 3. Manual Hyperparameter Tuning with Nested Cross-Validation ---\n",
    "results = []\n",
    "# Outer loop: Iterate through each hyperparameter combination\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"Testing params for imputation model: {params}\")\n",
    "    fold_scores = []\n",
    "    \n",
    "    # Inner loop: 5-Fold Cross-Validation\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    # Note: We split the original full dataframe indices to keep everything aligned\n",
    "    for train_idx, test_idx in cv.split(X_full):\n",
    "        \n",
    "        # --- Create data splits for this fold ---\n",
    "        # Correlated features for imputation\n",
    "        X_train_corr, X_test_corr = X_corr.iloc[train_idx], X_corr.iloc[test_idx]\n",
    "        # Full features for final model\n",
    "        X_train_full, X_test_full = X_full.iloc[train_idx], X_full.iloc[test_idx]\n",
    "        # Intermediate and final targets\n",
    "        y_train_intermediate, y_test_intermediate = y_intermediate.iloc[train_idx], y_intermediate.iloc[test_idx]\n",
    "        y_train_final, y_test_final = y_final.iloc[train_idx], y_final.iloc[test_idx]\n",
    "        \n",
    "        # --- Imputation Step (on the training data) ---\n",
    "        # a. Isolate the part of the training data where the intermediate target is known\n",
    "        X_train_corr_known_y = X_train_corr[y_train_intermediate.notna()]\n",
    "        y_train_intermediate_known_y = y_train_intermediate[y_train_intermediate.notna()]\n",
    "\n",
    "        # b. Fit the feature imputer ONLY on this known data subset\n",
    "        feature_imputer.fit(X_train_corr_known_y)\n",
    "        \n",
    "        # c. Train the target imputation model\n",
    "        target_imputer_model = KNeighborsRegressor(**params)\n",
    "        target_imputer_model.fit(feature_imputer.transform(X_train_corr_known_y), y_train_intermediate_known_y)\n",
    "        \n",
    "        # d. Impute missing intermediate values for both train and test sets\n",
    "        imputed_y_train = target_imputer_model.predict(feature_imputer.transform(X_train_corr))\n",
    "        imputed_y_test = target_imputer_model.predict(feature_imputer.transform(X_test_corr))\n",
    "\n",
    "        # --- Final Model Training and Evaluation ---\n",
    "        # e. Create the \"enhanced\" feature sets by adding the imputed variable\n",
    "        X_train_enhanced = X_train_full.copy()\n",
    "        X_train_enhanced['imputed_feature'] = imputed_y_train\n",
    "        \n",
    "        X_test_enhanced = X_test_full.copy()\n",
    "        X_test_enhanced['imputed_feature'] = imputed_y_test\n",
    "        \n",
    "        # f. Train the final model on the enhanced training data to predict the final target\n",
    "        main_model.fit(X_train_enhanced, y_train_final)\n",
    "        \n",
    "        # g. Make predictions on the enhanced test set\n",
    "        y_pred_final = main_model.predict(X_test_enhanced)\n",
    "        \n",
    "        # h. Evaluate final model performance and store the score\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_final, y_pred_final))\n",
    "        fold_scores.append(rmse)\n",
    "\n",
    "    # Calculate average score for the tested parameters\n",
    "    avg_score = np.mean(fold_scores)\n",
    "    results.append({'params': params, 'score': avg_score})\n",
    "    print(f\"  -> Average Final Model RMSE: {avg_score:.4f}\\n\")\n",
    "\n",
    "\n",
    "# --- 4. Find and Display the Best Parameters ---\n",
    "best_result = min(results, key=lambda x: x['score'])\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"üèÜ Best Hyperparameters for Imputation: {best_result['params']}\")\n",
    "print(f\"üèÜ Best Resulting Cross-Validated RMSE: {best_result['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da4a895-e3c4-41c0-83c9-df6180bf2f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaf3d6b-d094-4383-9130-c759090fd23c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c70374-c768-4300-a79c-6a2403331fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357dea5a-0868-493a-990c-73b194855ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50feda7-e742-4992-aa9f-b6bf1a0cbd67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
