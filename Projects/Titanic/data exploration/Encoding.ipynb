{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5061763-dee1-4b81-a223-cda34eef7a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "pd.options.mode.copy_on_write = True\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Set visualization style\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78dd8424-5943-4943-87e8-b03ed9711be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"C:\\Users\\basde\\OneDrive\\Documenten\\GitHub\\Titanic\\train.csv\")\n",
    "test = pd.read_csv(r\"C:\\Users\\basde\\OneDrive\\Documenten\\GitHub\\Titanic\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0102871-7695-4faf-baa3-2f107c4787e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad663c8b-f5ca-4d3a-b74a-3c9f74fef7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abc0d182-e623-465d-8627-9db102ea7192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin\n",
       "B57 B59 B63 B66    3\n",
       "B45                2\n",
       "C89                2\n",
       "C55 C57            2\n",
       "A34                2\n",
       "                  ..\n",
       "E52                1\n",
       "D30                1\n",
       "E31                1\n",
       "C62 C64            1\n",
       "C105               1\n",
       "Name: count, Length: 76, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Cabin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5676fbc2-5f9f-46ba-8a38-d9c96170566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PassengerId','Survived'], axis=1, inplace=True)\n",
    "test.drop('PassengerId', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe041ba7-e788-481e-8534-18fe42624925",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ca4d16f-ad50-4115-8a92-0e0cb24b8caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_order = ['male','female']\n",
    "ordinal_encoder = OrdinalEncoder(categories=[category_order])\n",
    "df['Sex'] = ordinal_encoder.fit_transform(df[['Sex']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc39e68d-65c9-459e-a60e-e71b906b8dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_order = ['male','female']\n",
    "ordinal_encoder = OrdinalEncoder(categories=[category_order])\n",
    "test['Sex'] = ordinal_encoder.fit_transform(test[['Sex']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5484f8b5-b3f0-4eb5-9b77-7f4617269bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# 1. Clean the Name column by removing text in parentheses and quotes\n",
    "df['Name'] = df['Name'].apply(lambda x: re.sub(r'\\([^)]*\\)', '', x).strip())\n",
    "df['Name'] = df['Name'].str.replace(r'\"[^\"]*\"', '', regex=True)\n",
    "\n",
    "# 2. Split Name into LastName and the rest\n",
    "df['LastName'] = df['Name'].str.split(',').str.get(0).str.strip()\n",
    "name_part = df['Name'].str.split(',').str.get(1).str.strip()\n",
    "\n",
    "# 3. Extract the Title from the remaining part of the name\n",
    "df['Titel'] = name_part.str.split('.').str.get(0).str.strip()\n",
    "\n",
    "# 4. Standardize the common titles\n",
    "title_mapping = {\n",
    "    'Mlle': 'Miss',\n",
    "    'Ms': 'Miss',\n",
    "    'Mme': 'Mrs'\n",
    "}\n",
    "df['Titel'] = df['Titel'].replace(title_mapping)\n",
    "\n",
    "# 5. Define a list of common titles\n",
    "common_titles = ['Mr', 'Miss', 'Mrs', 'Master']\n",
    "\n",
    "# 6. Categorize any title not in the common_titles list as 'Rare'\n",
    "df['Titel'] = df['Titel'].apply(lambda x: x if x in common_titles else 'Rare')\n",
    "\n",
    "df.drop(['Name', 'LastName'], axis=1, inplace=True)\n",
    "df['Titel'] = df['Titel'].apply(lambda x: x if x in common_titles else 'Rare')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "518f28f9-a429-47a1-b5e8-2434bb7df906",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['Titel'] = le.fit_transform(df['Titel'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6db31425-89c5-45d1-8d49-91d5f92b729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# 1. Clean the Name column by removing text in parentheses and quotes\n",
    "test['Name'] = test['Name'].apply(lambda x: re.sub(r'\\([^)]*\\)', '', x).strip())\n",
    "test['Name'] = test['Name'].str.replace(r'\"[^\"]*\"', '', regex=True)\n",
    "\n",
    "# 2. Split Name into LastName and the rest\n",
    "test['LastName'] = test['Name'].str.split(',').str.get(0).str.strip()\n",
    "name_part = test['Name'].str.split(',').str.get(1).str.strip()\n",
    "\n",
    "# 3. Extract the Title from the remaining part of the name\n",
    "test['Titel'] = name_part.str.split('.').str.get(0).str.strip()\n",
    "\n",
    "# 4. Standardize the common titles\n",
    "title_mapping = {\n",
    "    'Mlle': 'Miss',\n",
    "    'Ms': 'Miss',\n",
    "    'Mme': 'Mrs'\n",
    "}\n",
    "test['Titel'] = test['Titel'].replace(title_mapping)\n",
    "\n",
    "# 5. Define a list of common titles\n",
    "common_titles = ['Mr', 'Miss', 'Mrs', 'Master']\n",
    "\n",
    "# 6. Categorize any title not in the common_titles list as 'Rare'\n",
    "test['Titel'] = test['Titel'].apply(lambda x: x if x in common_titles else 'Rare')\n",
    "\n",
    "test.drop(['Name', 'LastName'], axis=1, inplace=True)\n",
    "test['Titel'] = test['Titel'].apply(lambda x: x if x in common_titles else 'Rare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a388b55c-595b-44b5-93bc-f5780250adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test['Titel'] = le.fit_transform(test['Titel'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04673351-767a-4450-82f4-4f320402ff3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        int64\n",
       "Sex         float64\n",
       "Age         float64\n",
       "SibSp         int64\n",
       "Parch         int64\n",
       "Ticket       object\n",
       "Fare        float64\n",
       "Cabin        object\n",
       "Embarked     object\n",
       "Titel         int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "874a59d0-74c5-42cd-8b3a-a47b9f10a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embarked'] = df['Embarked'].fillna('missing')\n",
    "test['Embarked'] = test['Embarked'].fillna('missing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bce689-a896-46bb-a9a8-b6ace14fb66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2935c9a-72eb-4907-932d-386d56baac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cabin'] = df['Cabin'].astype(str).str[0]\n",
    "test['Cabin'] = test['Cabin'].astype(str).str[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "559b0158-9fdf-4e5f-9aa8-2625221377cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cabin'] = le.fit_transform(df['Cabin'].astype(str))\n",
    "\n",
    "test['Cabin'] = le.transform(test['Cabin'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4947e0b1-7942-4f67-b08a-401871d89401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      8\n",
       "1      2\n",
       "2      8\n",
       "3      2\n",
       "4      8\n",
       "      ..\n",
       "886    8\n",
       "887    1\n",
       "888    8\n",
       "889    2\n",
       "890    8\n",
       "Name: Cabin, Length: 891, dtype: int32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cabin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32f5e19c-d6b7-4ca2-a616-3603ba99ee86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      8\n",
       "1      8\n",
       "2      8\n",
       "3      8\n",
       "4      8\n",
       "      ..\n",
       "413    8\n",
       "414    2\n",
       "415    8\n",
       "416    8\n",
       "417    8\n",
       "Name: Cabin, Length: 418, dtype: int32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Cabin'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "198cc608-d37f-45b2-bd59-6a8a0d4603fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embarked'] = le.fit_transform(df['Embarked'].astype(str))\n",
    "\n",
    "\n",
    "\n",
    "test['Embarked'] = le.transform(test['Embarked'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c9a20c9-0850-4482-983e-d5345bacf95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin\n",
       "8    687\n",
       "2     59\n",
       "1     47\n",
       "3     33\n",
       "4     32\n",
       "0     15\n",
       "5     13\n",
       "6      4\n",
       "7      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cabin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "feb5ab28-f201-4572-8d0f-9639b98888b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop('Ticket', axis=1)\n",
    "test1 = test.drop('Ticket', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f5b3b80-6aea-4cf3-8f0d-f89dbce5a8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Series name: Ticket\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "891 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 7.1+ KB\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Series name: Ticket\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "418 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df['Ticket'].info()\n",
    "test['Ticket'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "331d6616-4c01-4929-90aa-06b4eaab0630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imputer = IterativeImputer(min_value=1, random_state=0)\n",
    "df_imputed_array = imputer.fit_transform(df1)\n",
    "df1 = pd.DataFrame(df_imputed_array, columns=df1.columns)\n",
    "df1['Ticket'] = df['Ticket']\n",
    "df = df1\n",
    "test_imputed_array = imputer.transform(test1)\n",
    "test1 = pd.DataFrame(test_imputed_array, columns=test1.columns)\n",
    "test1['Ticket'] = test['Ticket']\n",
    "test = test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44745533-3f64-43a6-9f4d-30c7247d2b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Titel</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PC 17599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>113803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>373450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>211536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.155803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>W./C. 6607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>111369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>370376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age  SibSp  Parch     Fare  Cabin  Embarked  Titel  \\\n",
       "0       3.0  0.0  22.000000    1.0    0.0   7.2500    8.0       2.0    2.0   \n",
       "1       1.0  1.0  38.000000    1.0    0.0  71.2833    2.0       0.0    3.0   \n",
       "2       3.0  1.0  26.000000    0.0    0.0   7.9250    8.0       2.0    1.0   \n",
       "3       1.0  1.0  35.000000    1.0    0.0  53.1000    2.0       2.0    3.0   \n",
       "4       3.0  0.0  35.000000    0.0    0.0   8.0500    8.0       2.0    2.0   \n",
       "..      ...  ...        ...    ...    ...      ...    ...       ...    ...   \n",
       "886     2.0  0.0  27.000000    0.0    0.0  13.0000    8.0       2.0    4.0   \n",
       "887     1.0  1.0  19.000000    0.0    0.0  30.0000    1.0       2.0    1.0   \n",
       "888     3.0  1.0  15.155803    1.0    2.0  23.4500    8.0       2.0    1.0   \n",
       "889     1.0  0.0  26.000000    0.0    0.0  30.0000    2.0       0.0    2.0   \n",
       "890     3.0  0.0  32.000000    0.0    0.0   7.7500    8.0       1.0    2.0   \n",
       "\n",
       "               Ticket  \n",
       "0           A/5 21171  \n",
       "1            PC 17599  \n",
       "2    STON/O2. 3101282  \n",
       "3              113803  \n",
       "4              373450  \n",
       "..                ...  \n",
       "886            211536  \n",
       "887            112053  \n",
       "888        W./C. 6607  \n",
       "889            111369  \n",
       "890            370376  \n",
       "\n",
       "[891 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1b70c36-7be2-4cdd-90de-b0c973c72bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Titel</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>330911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>363272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>240276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>315154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3101298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.359807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC 17758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.359807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>359309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.979908</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age  SibSp  Parch      Fare  Cabin  Embarked  Titel  \\\n",
       "0       3.0  0.0  34.500000    0.0    0.0    7.8292    8.0       1.0    2.0   \n",
       "1       3.0  1.0  47.000000    1.0    0.0    7.0000    8.0       2.0    3.0   \n",
       "2       2.0  0.0  62.000000    0.0    0.0    9.6875    8.0       1.0    2.0   \n",
       "3       3.0  0.0  27.000000    0.0    0.0    8.6625    8.0       2.0    2.0   \n",
       "4       3.0  1.0  22.000000    1.0    1.0   12.2875    8.0       2.0    3.0   \n",
       "..      ...  ...        ...    ...    ...       ...    ...       ...    ...   \n",
       "413     3.0  0.0  29.359807    0.0    0.0    8.0500    8.0       2.0    2.0   \n",
       "414     1.0  1.0  39.000000    0.0    0.0  108.9000    2.0       0.0    4.0   \n",
       "415     3.0  0.0  38.500000    0.0    0.0    7.2500    8.0       2.0    2.0   \n",
       "416     3.0  0.0  29.359807    0.0    0.0    8.0500    8.0       2.0    2.0   \n",
       "417     3.0  0.0   9.979908    1.0    1.0   22.3583    8.0       0.0    0.0   \n",
       "\n",
       "                 Ticket  \n",
       "0                330911  \n",
       "1                363272  \n",
       "2                240276  \n",
       "3                315154  \n",
       "4               3101298  \n",
       "..                  ...  \n",
       "413           A.5. 3236  \n",
       "414            PC 17758  \n",
       "415  SOTON/O.Q. 3101262  \n",
       "416              359309  \n",
       "417                2668  \n",
       "\n",
       "[418 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c04e4-a108-4097-8a24-cf841d351539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ffe177c-3334-4556-ab34-25226f02e91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of unique values: 681\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\\nNumber of unique values: {df['Ticket'].nunique()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d51755e1-0e3b-4fb6-a005-3dabe361436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Ticket']\n",
    "y = train['Survived']\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import category_encoders as ce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1814f089-6f6f-4ea9-9620-b074e16250ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Cross-Validation for Hashing Encoder...\n",
      "\n",
      "--- Testing with 8 Columns ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ce' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Testing with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_components\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Columns ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Define the Hashing Encoder with the current number of components\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# handle_unknown is set to 'return_nan' and then imputed to avoid errors if a fold is missing a category\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m encoder \u001b[38;5;241m=\u001b[39m \u001b[43mce\u001b[49m\u001b[38;5;241m.\u001b[39mHashingEncoder(n_components\u001b[38;5;241m=\u001b[39mn_components)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Define the classifier\u001b[39;00m\n\u001b[0;32m     13\u001b[0m classifier \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ce' is not defined"
     ]
    }
   ],
   "source": [
    "n_components_to_test = [8, 16, 32, 64, 128, 256]\n",
    "\n",
    "print(\"ðŸš€ Starting Cross-Validation for Hashing Encoder...\\n\")\n",
    "\n",
    "for n_components in n_components_to_test:\n",
    "    print(f\"--- Testing with {n_components} Columns ---\")\n",
    "\n",
    "    # Define the Hashing Encoder with the current number of components\n",
    "    # handle_unknown is set to 'return_nan' and then imputed to avoid errors if a fold is missing a category\n",
    "    encoder = ce.HashingEncoder(n_components=n_components)\n",
    "\n",
    "    # Define the classifier\n",
    "    classifier = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "    # Create the full pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('encoder', encoder),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    # We ask it to return the training scores as well\n",
    "    cv_scores = cross_validate(\n",
    "        pipeline,\n",
    "        X,\n",
    "        y,\n",
    "        cv=5,  # 5 folds\n",
    "        scoring='accuracy',\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1 # Use all available CPU cores\n",
    "    )\n",
    "\n",
    "    # --- 3. Print the Results for the Current Number of Columns ---\n",
    "    print(f\"Average Training Score: {np.mean(cv_scores['train_score']):.4f}\")\n",
    "    print(f\"Validation Score per Fold: {[f'{score:.4f}' for score in cv_scores['test_score']]}\")\n",
    "    print(f\"Average Validation Score: {np.mean(cv_scores['test_score']):.4f} (+/- {np.std(cv_scores['test_score']):.4f})\")\n",
    "    print(\"-\" * 40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5122d6c-306e-4dae-a51e-0f6fd40fed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fare'] = np.log1p(df['Fare'])\n",
    "test['Fare'] = np.log1p(test['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf4867e-c860-4b4e-84fd-b708d959890e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5487c595-430d-4362-8ae8-98ad41f82092",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df\n",
    "X_baseline = df.drop(['Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77a97018-5aea-43b2-bd5a-3fe757fbb8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked',\n",
       "       'Titel'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_baseline.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6c39ad4-8b4b-4fb1-9205-5667feb4a17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "886    0\n",
       "887    1\n",
       "888    0\n",
       "889    1\n",
       "890    0\n",
       "Name: Survived, Length: 891, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e35b8921-f79d-41a0-95ec-fca343eeb6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Baseline CV Score (Numerical Features ONLY): 0.8081\n",
      "ðŸš€ Full Model CV Score (Categorical + Numerical): 0.8294\n",
      "--------------------------------------------------\n",
      "âœ… Performance lift from adding the categorical feature: +0.0213\n",
      "\n",
      "Conclusion: The effect is still significant! The categorical feature adds unique predictive value.\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "\n",
    "# --- 3. Run CV on the BASELINE Model (Numerical Features Only) ---\n",
    "# No special encoding needed for the baseline model\n",
    "pipeline_baseline = Pipeline(steps=[('classifier', classifier)])\n",
    "\n",
    "cv_scores_baseline = cross_validate(\n",
    "    pipeline_baseline,\n",
    "    X_baseline,\n",
    "    y,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "baseline_score = np.mean(cv_scores_baseline['test_score'])\n",
    "print(f\"ðŸ“Š Baseline CV Score (Numerical Features ONLY): {baseline_score:.4f}\")\n",
    "\n",
    "\n",
    "# --- 4. Run CV on the FULL Model (Categorical + Numerical) ---\n",
    "# We need a ColumnTransformer to apply hashing ONLY to the categorical column\n",
    "categorical_cols = ['Ticket']\n",
    "numerical_cols = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
    "       'Cabin', 'Embarked', 'Titel']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Use 32 components as determined before\n",
    "        ('cat_hasher', ce.HashingEncoder(n_components=16), categorical_cols),\n",
    "        # 'passthrough' means the numerical columns won't be changed\n",
    "        ('num_pass', 'passthrough', numerical_cols)\n",
    "    ],\n",
    "    remainder='drop' # Drop any other columns not specified\n",
    ")\n",
    "\n",
    "pipeline_full = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "cv_scores_full = cross_validate(\n",
    "    pipeline_full,\n",
    "    X_full,\n",
    "    y,\n",
    "    cv=10,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "full_model_score = np.mean(cv_scores_full['test_score'])\n",
    "print(f\"ðŸš€ Full Model CV Score (Categorical + Numerical): {full_model_score:.4f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 5. Conclusion ---\n",
    "performance_lift = full_model_score - baseline_score\n",
    "print(f\"âœ… Performance lift from adding the categorical feature: {performance_lift:+.4f}\")\n",
    "\n",
    "if performance_lift > 0.01:\n",
    "    print(\"\\nConclusion: The effect is still significant! The categorical feature adds unique predictive value.\")\n",
    "elif performance_lift > 0:\n",
    "    print(\"\\nConclusion: The feature adds a small amount of value, but the other features are more dominant.\")\n",
    "else:\n",
    "    print(\"\\nConclusion: The feature does not add predictive value when other features are present.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d564d73b-59c9-437a-b153-23890b684e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasher = ce.HashingEncoder(n_components=16)\n",
    "hashed_column_df = hasher.fit_transform(test[['Ticket']])\n",
    "test = pd.concat([test.drop(columns=['Ticket']), hashed_column_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f0397ef-f780-4ae7-90a0-27cb43dfa77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashed_column_df = hasher.fit_transform(df[['Ticket']])\n",
    "df = pd.concat([df.drop(columns=['Ticket']), hashed_column_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fba8207a-9fee-457e-8d43-46c9c990b278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked',\n",
       "       'Titel', 'col_0', 'col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6',\n",
       "       'col_7', 'col_8', 'col_9', 'col_10', 'col_11', 'col_12', 'col_13',\n",
       "       'col_14', 'col_15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "900a5a78-0c8f-47a9-b466-63e384b0f409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked',\n",
       "       'Titel', 'col_0', 'col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6',\n",
       "       'col_7', 'col_8', 'col_9', 'col_10', 'col_11', 'col_12', 'col_13',\n",
       "       'col_14', 'col_15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3bae16b3-1e18-4a79-88cf-c0713b5197e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "y= train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8313a90-96d5-496c-9702-d176891e876a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Titel</th>\n",
       "      <th>col_0</th>\n",
       "      <th>...</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>col_10</th>\n",
       "      <th>col_11</th>\n",
       "      <th>col_12</th>\n",
       "      <th>col_13</th>\n",
       "      <th>col_14</th>\n",
       "      <th>col_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.188856</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.990834</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.155803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.196630</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.169054</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age  SibSp  Parch      Fare  Cabin  Embarked  Titel  \\\n",
       "0       3.0  0.0  22.000000    1.0    0.0  2.110213    8.0       2.0    2.0   \n",
       "1       1.0  1.0  38.000000    1.0    0.0  4.280593    2.0       0.0    3.0   \n",
       "2       3.0  1.0  26.000000    0.0    0.0  2.188856    8.0       2.0    1.0   \n",
       "3       1.0  1.0  35.000000    1.0    0.0  3.990834    2.0       2.0    3.0   \n",
       "4       3.0  0.0  35.000000    0.0    0.0  2.202765    8.0       2.0    2.0   \n",
       "..      ...  ...        ...    ...    ...       ...    ...       ...    ...   \n",
       "886     2.0  0.0  27.000000    0.0    0.0  2.639057    8.0       2.0    4.0   \n",
       "887     1.0  1.0  19.000000    0.0    0.0  3.433987    1.0       2.0    1.0   \n",
       "888     3.0  1.0  15.155803    1.0    2.0  3.196630    8.0       2.0    1.0   \n",
       "889     1.0  0.0  26.000000    0.0    0.0  3.433987    2.0       0.0    2.0   \n",
       "890     3.0  0.0  32.000000    0.0    0.0  2.169054    8.0       1.0    2.0   \n",
       "\n",
       "     col_0  ...  col_6  col_7  col_8  col_9  col_10  col_11  col_12  col_13  \\\n",
       "0        0  ...      0      0      0      0       1       0       0       0   \n",
       "1        0  ...      0      0      0      0       0       0       0       0   \n",
       "2        0  ...      0      0      0      0       0       0       0       0   \n",
       "3        0  ...      0      1      0      0       0       0       0       0   \n",
       "4        0  ...      0      0      0      0       0       0       1       0   \n",
       "..     ...  ...    ...    ...    ...    ...     ...     ...     ...     ...   \n",
       "886      0  ...      0      0      0      0       0       0       0       0   \n",
       "887      0  ...      0      0      0      0       0       0       0       0   \n",
       "888      0  ...      0      0      0      1       0       0       0       0   \n",
       "889      0  ...      0      0      0      0       0       0       1       0   \n",
       "890      0  ...      0      0      0      0       1       0       0       0   \n",
       "\n",
       "     col_14  col_15  \n",
       "0         0       0  \n",
       "1         0       1  \n",
       "2         0       0  \n",
       "3         0       0  \n",
       "4         0       0  \n",
       "..      ...     ...  \n",
       "886       1       0  \n",
       "887       0       0  \n",
       "888       0       0  \n",
       "889       0       0  \n",
       "890       0       0  \n",
       "\n",
       "[891 rows x 25 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9568ce23-fadd-4731-88b7-925878f5ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "# Ensemble and Boosting models\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import cross_validate\n",
    "# --- Model Evaluation Tools ---\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4731f268-bd30-470d-a5b5-78f1c6b38a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(solver='liblinear'),\n",
    "    \"Ridge Classifier\": RidgeClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"SVC\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": xgb.XGBClassifier(eval_metric='logloss'),\n",
    "    \"CatBoost\": cb.CatBoostClassifier(verbose=0),\n",
    "    \"MLP Classifier\": MLPClassifier(max_iter=500, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "75ae435f-02bb-4cb9-aacc-6e05e6c3f1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models...\n",
      "Logistic Regression:\n",
      "  Training Accuracy: 0.8092 (+/- 0.0053)\n",
      "  CV Accuracy: 0.8024 (+/- 0.0350)\n",
      "------------------------------\n",
      "Ridge Classifier:\n",
      "  Training Accuracy: 0.8065 (+/- 0.0056)\n",
      "  CV Accuracy: 0.8058 (+/- 0.0364)\n",
      "------------------------------\n",
      "Gaussian Naive Bayes:\n",
      "  Training Accuracy: 0.7618 (+/- 0.0071)\n",
      "  CV Accuracy: 0.7475 (+/- 0.0279)\n",
      "------------------------------\n",
      "K-Nearest Neighbors:\n",
      "  Training Accuracy: 0.8375 (+/- 0.0070)\n",
      "  CV Accuracy: 0.7631 (+/- 0.0409)\n",
      "------------------------------\n",
      "SVC:\n",
      "  Training Accuracy: 0.7248 (+/- 0.0061)\n",
      "  CV Accuracy: 0.7149 (+/- 0.0461)\n",
      "------------------------------\n",
      "Decision Tree:\n",
      "  Training Accuracy: 0.9949 (+/- 0.0007)\n",
      "  CV Accuracy: 0.7710 (+/- 0.0359)\n",
      "------------------------------\n",
      "Random Forest:\n",
      "  Training Accuracy: 0.9948 (+/- 0.0005)\n",
      "  CV Accuracy: 0.8271 (+/- 0.0305)\n",
      "------------------------------\n",
      "AdaBoost:\n",
      "  Training Accuracy: 0.8313 (+/- 0.0038)\n",
      "  CV Accuracy: 0.8237 (+/- 0.0316)\n",
      "------------------------------\n",
      "Gradient Boosting:\n",
      "  Training Accuracy: 0.9162 (+/- 0.0064)\n",
      "  CV Accuracy: 0.8259 (+/- 0.0389)\n",
      "------------------------------\n",
      "XGBoost:\n",
      "  Training Accuracy: 0.9877 (+/- 0.0021)\n",
      "  CV Accuracy: 0.8148 (+/- 0.0235)\n",
      "------------------------------\n",
      "CatBoost:\n",
      "  Training Accuracy: 0.9312 (+/- 0.0044)\n",
      "  CV Accuracy: 0.8350 (+/- 0.0249)\n",
      "------------------------------\n",
      "MLP Classifier:\n",
      "  Training Accuracy: 0.8247 (+/- 0.0140)\n",
      "  CV Accuracy: 0.8058 (+/- 0.0270)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "print(\"Evaluating models...\")\n",
    "for name, model in models.items():\n",
    "    # 1. Define the cross-validation strategy\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    # 2. Perform cross-validation using cross_validate\n",
    "    # Set return_train_score=True to get training scores\n",
    "    cv_results = cross_validate(model, X, y, cv=cv, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "    # 3. Store the results (now a dictionary)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "\n",
    "    # 4. Calculate and print the mean and std dev for both train and CV scores\n",
    "    train_score_mean = cv_results['train_score'].mean()\n",
    "    train_score_std = cv_results['train_score'].std()\n",
    "    cv_score_mean = cv_results['test_score'].mean()\n",
    "    cv_score_std = cv_results['test_score'].std()\n",
    "\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Training Accuracy: {train_score_mean:.4f} (+/- {train_score_std:.4f})\")\n",
    "    print(f\"  CV Accuracy: {cv_score_mean:.4f} (+/- {cv_score_std:.4f})\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be20f36d-1f68-4f0a-9e92-53d63ffe7603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Present Results in a DataFrame ---\n",
    "# # Create a DataFrame to hold the results for easy comparison\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Model': names,\n",
    "#     'Mean Accuracy': [res.mean() for res in results],\n",
    "#     'Std Dev': [res.std() for res in results]\n",
    "# })\n",
    "\n",
    "# # Sort the models by mean accuracy in descending order\n",
    "# sorted_results_df = results_df.sort_values(by='Mean Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# print(\"\\n--- Model Performance Comparison ---\")\n",
    "# print(sorted_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2372599-efbd-4bb7-81cc-90f476ccefef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f72bd80-b25c-46f6-afef-947993be42aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸš€ Starting CatBoost Hyperparameter Tuning...\")\n",
    "\n",
    "# --- 1. Define the model ---\n",
    "# Pass `silent=True` to let GridSearchCV control the verbosity\n",
    "cat = CatBoostClassifier(random_state=42, silent=True)\n",
    "\n",
    "# --- 2. Define a comprehensive hyperparameter grid ---\n",
    "# WARNING: Also a large grid, will be computationally expensive!\n",
    "cat_param_grid = {\n",
    "    'iterations': [200, 500],\n",
    "    'learning_rate': [0.01, 0.05],\n",
    "    'depth': [4, 5, 6],\n",
    "    'l2_leaf_reg': [3, 5, 7],\n",
    "    'subsample': [0.7, 0.8],\n",
    "    'rsm': [0.7, 0.8] \n",
    "}     \n",
    "\n",
    "\n",
    "# --- 3. Set up GridSearchCV ---\n",
    "cat_grid_search = GridSearchCV(\n",
    "    estimator=cat,\n",
    "    param_grid=cat_param_grid,\n",
    "    cv=cv_strategy,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=3,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# --- 4. Run the search ---\n",
    "cat_grid_search.fit(X, y)\n",
    "\n",
    "# --- 5. Display the results ---\n",
    "print(\"\\nâœ… CatBoost Tuning Complete!\")\n",
    "print(f\"Best CatBoost Parameters: {cat_grid_search.best_params_}\")\n",
    "print(f\"Best CatBoost CV Score: {cat_grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "cat_results_df = pd.DataFrame(cat_grid_search.cv_results_)\n",
    "\n",
    "# Columns to display\n",
    "display_cols_cat = [\n",
    "    'param_iterations', 'param_depth', 'param_learning_rate',\n",
    "    'mean_train_score', 'std_train_score',\n",
    "    'mean_test_score', 'std_test_score',\n",
    "    'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score'\n",
    "]\n",
    "\n",
    "# Sort by the best CV score and show the top 5 combinations\n",
    "print(\"\\nTop 5 CatBoost Hyperparameter Combinations:\")\n",
    "display(cat_results_df.sort_values(by='rank_test_score').head(5)[display_cols_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7e066b-1f9e-40ec-b9d3-2bdce589f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸš€ Starting XGBoost Hyperparameter Tuning...\")\n",
    "\n",
    "# --- 1. Define the model ---\n",
    "xgb = XGBClassifier(objective='binary:logistic', eval_metric='logloss', random_state=42)\n",
    "\n",
    "# --- 2. Define a comprehensive hyperparameter grid ---\n",
    "# WARNING: This is a large grid and will be computationally expensive!\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [200, 400],\n",
    "    'learning_rate': [0.01, 0.05],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'subsample': [0.7, 0.8],\n",
    "    'colsample_bytree': [0.7, 0.8],\n",
    "    'gamma': [0.1, 0.5, 1],\n",
    "    'reg_alpha': [0, 0.1],\n",
    "    'reg_lambda': [1, 1.5]\n",
    "}      # L1 regularization\n",
    "\n",
    "\n",
    "\n",
    "# --- 3. Set up GridSearchCV ---\n",
    "# We set `return_train_score=True` to get the training scores\n",
    "# `verbose=3` gives detailed output during the search\n",
    "xgb_grid_search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=xgb_param_grid,\n",
    "    cv=cv_strategy,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  # Use all available CPU cores\n",
    "    verbose=3,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# --- 4. Run the search ---\n",
    "xgb_grid_search.fit(X, y)\n",
    "\n",
    "# --- 5. Display the results ---\n",
    "print(\"\\nâœ… XGBoost Tuning Complete!\")\n",
    "print(f\"Best XGBoost Parameters: {xgb_grid_search.best_params_}\")\n",
    "print(f\"Best XGBoost CV Score: {xgb_grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Convert results to a DataFrame for detailed analysis\n",
    "xgb_results_df = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "\n",
    "# Columns to display for a clear overview\n",
    "# This includes mean scores and scores for each individual fold\n",
    "display_cols = [\n",
    "    'param_n_estimators', 'param_max_depth', 'param_learning_rate',\n",
    "    'mean_train_score', 'std_train_score',\n",
    "    'mean_test_score', 'std_test_score',\n",
    "    'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score'\n",
    "]\n",
    "\n",
    "# Sort by the best CV score and show the top 5 combinations\n",
    "print(\"\\nTop 5 XGBoost Hyperparameter Combinations:\")\n",
    "display(xgb_results_df.sort_values(by='rank_test_score').head(5)[display_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15c1ca5-8cae-4067-957e-c865b6267910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# This code assumes X, y, and cv_strategy are already defined from the previous examples.\n",
    "\n",
    "print(\"ðŸš€ Starting Gradient Boosting Hyperparameter Tuning...\")\n",
    "\n",
    "# --- 1. Define the model ---\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# --- 2. Define a comprehensive hyperparameter grid ---\n",
    "# WARNING: This is a large grid and will be computationally expensive!\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [200, 400],\n",
    "    'learning_rate': [0.01, 0.05],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'subsample': [0.7, 0.8],\n",
    "    'max_features': ['sqrt', 0.7],\n",
    "    'min_samples_leaf': [3, 5]         # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# --- 3. Set up GridSearchCV ---\n",
    "gb_grid_search = GridSearchCV(\n",
    "    estimator=gb,\n",
    "    param_grid=gb_param_grid,\n",
    "    cv=cv_strategy,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  # Use all available CPU cores\n",
    "    verbose=3,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# --- 4. Run the search ---\n",
    "gb_grid_search.fit(X, y)\n",
    "\n",
    "# --- 5. Display the results ---\n",
    "print(\"\\nâœ… Gradient Boosting Tuning Complete!\")\n",
    "print(f\"Best Gradient Boosting Parameters: {gb_grid_search.best_params_}\")\n",
    "print(f\"Best Gradient Boosting CV Score: {gb_grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Convert results to a DataFrame for detailed analysis\n",
    "gb_results_df = pd.DataFrame(gb_grid_search.cv_results_)\n",
    "\n",
    "# Columns to display for a clear overview\n",
    "display_cols_gb = [\n",
    "    'param_n_estimators', 'param_max_depth', 'param_learning_rate', 'param_subsample',\n",
    "    'mean_train_score',\n",
    "    'mean_test_score',\n",
    "    'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score'\n",
    "]\n",
    "\n",
    "# Sort by the best CV score and show the top 5 combinations\n",
    "print(\"\\nTop 5 Gradient Boosting Hyperparameter Combinations:\")\n",
    "display(gb_results_df.sort_values(by='rank_test_score').head(5)[display_cols_gb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5639390-b53a-48b7-80f7-04832c0c4006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "# This code assumes X, y, and cv_strategy are already defined from the previous examples.\n",
    "\n",
    "print(\"ðŸš€ Starting AdaBoost Hyperparameter Tuning...\")\n",
    "\n",
    "# --- 1. Define the model ---\n",
    "# We use a DecisionTreeClassifier as the base estimator to tune its depth.\n",
    "ada = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(random_state=42),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- 2. Define Hyperparameter Grids ---\n",
    "\n",
    "# -- Grid 1: Focused Grid for General Tuning --\n",
    "ada_param_grid_focused = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'learning_rate': [0.05, 0.1, 0.5, 1.0],\n",
    "    # Note the '__' syntax to access the base estimator's parameters\n",
    "    'estimator__max_depth': [1, 2, 3]\n",
    "}\n",
    "\n",
    "\n",
    "# -- Grid 2: Grid to Specifically Combat Overfitting --\n",
    "# This grid uses a lower learning rate and very simple base estimators.\n",
    "ada_param_grid_overfit = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.05],\n",
    "    'estimator__max_depth': [1, 2] # Stumps (depth=1) are best for low variance\n",
    "}\n",
    "\n",
    "\n",
    "# --- 3. Set up GridSearchCV ---\n",
    "# We'll use the focused grid for this example. Change to `ada_param_grid_overfit` if needed.\n",
    "ada_grid_search = GridSearchCV(\n",
    "    estimator=ada,\n",
    "    param_grid=ada_param_grid_focused,\n",
    "    cv=cv_strategy,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=3,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# --- 4. Run the search ---\n",
    "ada_grid_search.fit(X, y)\n",
    "\n",
    "# --- 5. Display the results ---\n",
    "print(\"\\nâœ… AdaBoost Tuning Complete!\")\n",
    "print(f\"Best AdaBoost Parameters: {ada_grid_search.best_params_}\")\n",
    "print(f\"Best AdaBoost CV Score: {ada_grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Convert results to a DataFrame for detailed analysis\n",
    "ada_results_df = pd.DataFrame(ada_grid_search.cv_results_)\n",
    "\n",
    "# Display top results\n",
    "print(\"\\nTop 5 AdaBoost Hyperparameter Combinations:\")\n",
    "display(ada_results_df.sort_values(by='rank_test_score').head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ba06f6-3b76-4100-b5ca-2844e8c169a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1. Assume your grid search objects are fitted ---\n",
    "# For example: xgb_grid_search, cat_grid_search, ada_grid_search\n",
    "# We'll use placeholder results for this demonstration.\n",
    "# In your code, you would extract these from the actual grid search objects.\n",
    "\n",
    "# Example placeholder objects (replace with your actual fitted grid searches)\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# X, y = [[0,0],[1,1]], [0,1]\n",
    "# xgb_grid_search = GridSearchCV(LogisticRegression(), {}, cv=2).fit(X,y)\n",
    "# cat_grid_search = GridSearchCV(LogisticRegression(), {}, cv=2).fit(X,y)\n",
    "# ada_grid_search = GridSearchCV(LogisticRegression(), {}, cv=2).fit(X,y)\n",
    "\n",
    "\n",
    "# --- 2. Gather results from each model ---\n",
    "all_model_results = []\n",
    "grid_searches = {\n",
    "    \"XGBoost\": xgb_grid_search,\n",
    "    \"CatBoost\": cat_grid_search,\n",
    "    \"AdaBoost\": ada_grid_search\n",
    "    # Add other fitted grid search objects here\n",
    "}\n",
    "\n",
    "for name, gs in grid_searches.items():\n",
    "    # Find the index of the best score\n",
    "    best_index = gs.best_index_\n",
    "\n",
    "    # Get the corresponding CV (test) and train scores\n",
    "    cv_score = gs.cv_results_['mean_test_score'][best_index]\n",
    "    train_score = gs.cv_results_['mean_train_score'][best_index]\n",
    "\n",
    "    all_model_results.append({\n",
    "        \"Model\": name,\n",
    "        \"CV Score\": cv_score,\n",
    "        \"Train Score\": train_score,\n",
    "        \"Best Params\": gs.best_params_\n",
    "    })\n",
    "\n",
    "# --- 3. Create and process the DataFrame ---\n",
    "results_df = pd.DataFrame(all_model_results)\n",
    "\n",
    "# Calculate the overfitting gap and the new adjusted score\n",
    "results_df[\"Overfitting\"] = results_df[\"Train Score\"] - results_df[\"CV Score\"]\n",
    "results_df[\"Adjusted Score\"] = results_df[\"CV Score\"] - results_df[\"Overfitting\"]\n",
    "\n",
    "# Sort the DataFrame by the new adjusted score\n",
    "ranked_df = results_df.sort_values(by=\"Adjusted Score\", ascending=False)\n",
    "\n",
    "\n",
    "# --- 4. Display the final ranked list ---\n",
    "print(\"ðŸ† Ranked Model Leaderboard ðŸ†\")\n",
    "display(ranked_df[['Model', 'Adjusted Score', 'CV Score', 'Overfitting', 'Train Score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "184bb4aa-e6eb-4ad3-aeef-1d399e179d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(X, pd.DataFrame):\n",
    "    X = X.values\n",
    "else:\n",
    "    X = X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "22fdebd7-2c06-45de-9d0f-1d1953a8ab43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Titel</th>\n",
       "      <th>col_0</th>\n",
       "      <th>...</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>col_10</th>\n",
       "      <th>col_11</th>\n",
       "      <th>col_12</th>\n",
       "      <th>col_13</th>\n",
       "      <th>col_14</th>\n",
       "      <th>col_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.188856</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.990834</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.155803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.196630</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.169054</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age  SibSp  Parch      Fare  Cabin  Embarked  Titel  \\\n",
       "0       3.0  0.0  22.000000    1.0    0.0  2.110213    8.0       2.0    2.0   \n",
       "1       1.0  1.0  38.000000    1.0    0.0  4.280593    2.0       0.0    3.0   \n",
       "2       3.0  1.0  26.000000    0.0    0.0  2.188856    8.0       2.0    1.0   \n",
       "3       1.0  1.0  35.000000    1.0    0.0  3.990834    2.0       2.0    3.0   \n",
       "4       3.0  0.0  35.000000    0.0    0.0  2.202765    8.0       2.0    2.0   \n",
       "..      ...  ...        ...    ...    ...       ...    ...       ...    ...   \n",
       "886     2.0  0.0  27.000000    0.0    0.0  2.639057    8.0       2.0    4.0   \n",
       "887     1.0  1.0  19.000000    0.0    0.0  3.433987    1.0       2.0    1.0   \n",
       "888     3.0  1.0  15.155803    1.0    2.0  3.196630    8.0       2.0    1.0   \n",
       "889     1.0  0.0  26.000000    0.0    0.0  3.433987    2.0       0.0    2.0   \n",
       "890     3.0  0.0  32.000000    0.0    0.0  2.169054    8.0       1.0    2.0   \n",
       "\n",
       "     col_0  ...  col_6  col_7  col_8  col_9  col_10  col_11  col_12  col_13  \\\n",
       "0        0  ...      0      0      0      0       1       0       0       0   \n",
       "1        0  ...      0      0      0      0       0       0       0       0   \n",
       "2        0  ...      0      0      0      0       0       0       0       0   \n",
       "3        0  ...      0      1      0      0       0       0       0       0   \n",
       "4        0  ...      0      0      0      0       0       0       1       0   \n",
       "..     ...  ...    ...    ...    ...    ...     ...     ...     ...     ...   \n",
       "886      0  ...      0      0      0      0       0       0       0       0   \n",
       "887      0  ...      0      0      0      0       0       0       0       0   \n",
       "888      0  ...      0      0      0      1       0       0       0       0   \n",
       "889      0  ...      0      0      0      0       0       0       1       0   \n",
       "890      0  ...      0      0      0      0       1       0       0       0   \n",
       "\n",
       "     col_14  col_15  \n",
       "0         0       0  \n",
       "1         0       1  \n",
       "2         0       0  \n",
       "3         0       0  \n",
       "4         0       0  \n",
       "..      ...     ...  \n",
       "886       1       0  \n",
       "887       0       0  \n",
       "888       0       0  \n",
       "889       0       0  \n",
       "890       0       0  \n",
       "\n",
       "[891 rows x 25 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08072222-73fd-412c-a44e-856c2a7d8f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1. Set your penalty factor ---\n",
    "# - Set to 1.0 for the original aggressive penalty.\n",
    "# - Set to 0.5 to balance performance and overfitting (recommended start).\n",
    "# - Set to 0.25 to lightly penalize overfitting.\n",
    "overfitting_penalty = 0.5\n",
    "\n",
    "\n",
    "# --- 2. Assume your grid search objects are fitted ---\n",
    "# (Using the same setup as before)\n",
    "all_model_results = []\n",
    "grid_searches = {\n",
    "    \"XGBoost\": xgb_grid_search,\n",
    "    \"CatBoost\": cat_grid_search,\n",
    "    \"AdaBoost\": ada_grid_search,\n",
    "    \"ADABoost2\": grid_search\n",
    "}\n",
    "\n",
    "for name, gs in grid_searches.items():\n",
    "    best_index = gs.best_index_\n",
    "    cv_score = gs.cv_results_['mean_test_score'][best_index]\n",
    "    train_score = gs.cv_results_['mean_train_score'][best_index]\n",
    "\n",
    "    all_model_results.append({\n",
    "        \"Model\": name,\n",
    "        \"CV Score\": cv_score,\n",
    "        \"Train Score\": train_score,\n",
    "    })\n",
    "\n",
    "\n",
    "# --- 3. Create and process the DataFrame with the new formula ---\n",
    "results_df = pd.DataFrame(all_model_results)\n",
    "\n",
    "results_df[\"Overfitting\"] = results_df[\"Train Score\"] - results_df[\"CV Score\"]\n",
    "results_df[\"Adjusted Score\"] = results_df[\"CV Score\"] - (overfitting_penalty * results_df[\"Overfitting\"])\n",
    "\n",
    "# Sort the DataFrame by the new adjusted score\n",
    "ranked_df = results_df.sort_values(by=\"Adjusted Score\", ascending=False)\n",
    "\n",
    "\n",
    "# --- 4. Display the final ranked list ---\n",
    "print(f\"ðŸ† Ranked Model Leaderboard (Penalty Factor: {overfitting_penalty}) ðŸ†\")\n",
    "display(ranked_df[['Model', 'Adjusted Score', 'CV Score', 'Overfitting', 'Train Score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "92df8e11-137f-410d-bae9-4e56a37e06ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "\n",
      "âœ… Tuning Complete!\n",
      "Best Parameters Found: {'estimator__max_depth': 1, 'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Best Adjusted Score: 0.7709\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_validate\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# --- 1. Define the custom scoring logic in a function ---\n",
    "# This part remains the same.\n",
    "def adjusted_scorer_func(estimator, X, y):\n",
    "    \"\"\"\n",
    "    A custom scorer that calculates CV score minus a penalty for overfitting.\n",
    "    \"\"\"\n",
    "    overfitting_penalty = 0.2\n",
    "    results = cross_validate(\n",
    "        estimator, X, y,\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        scoring='accuracy',\n",
    "        return_train_score=True\n",
    "    )\n",
    "    cv_score = np.mean(results['test_score'])\n",
    "    train_score = np.mean(results['train_score'])\n",
    "    overfitting_gap = train_score - cv_score\n",
    "    adjusted_score = cv_score - (overfitting_penalty * overfitting_gap)\n",
    "    return adjusted_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the model and a parameter grid\n",
    "ada = AdaBoostClassifier(estimator=DecisionTreeClassifier(random_state=42), random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200], # Wider range around and above 50-100\n",
    "    'learning_rate': [0.1, 0.5, 1], # Wider range, including lower values\n",
    "    'estimator__max_depth': [1, 3]\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV using the function directly in the 'scoring' parameter\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ada,\n",
    "    param_grid=param_grid,\n",
    "    scoring=adjusted_scorer_func, # <-- Pass the function directly\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Run the search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# --- 3. Analyze the results ---\n",
    "print(\"\\nâœ… Tuning Complete!\")\n",
    "print(f\"Best Parameters Found: {grid_search.best_params_}\")\n",
    "print(f\"Best Adjusted Score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d083b2d0-267c-40aa-87db-31c616d27616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of Best Model (from GridSearchCV with Adjusted Score):\n",
      "  Training Accuracy: 0.7873 (+/- 0.0037)\n",
      "  CV Accuracy: 0.7868 (+/- 0.0188)\n",
      "  Train-CV Gap: 0.0006\n"
     ]
    }
   ],
   "source": [
    "# After grid_search.fit(X, y)\n",
    "best_ada_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model with standard accuracy\n",
    "results_best_model = cross_validate(\n",
    "    best_ada_model, X, y,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='accuracy',\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nEvaluation of Best Model (from GridSearchCV with Adjusted Score):\")\n",
    "print(f\"  Training Accuracy: {np.mean(results_best_model['train_score']):.4f} (+/- {np.std(results_best_model['train_score']):.4f})\")\n",
    "print(f\"  CV Accuracy: {np.mean(results_best_model['test_score']):.4f} (+/- {np.std(results_best_model['test_score']):.4f})\")\n",
    "print(f\"  Train-CV Gap: {np.mean(results_best_model['train_score']) - np.mean(results_best_model['test_score']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f34ebc06-9611-469c-bbbc-1bd276cb6223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Found:\n",
      "{'estimator__max_depth': 1, 'learning_rate': 0.1, 'n_estimators': 50}\n",
      "\n",
      "Best Adjusted Score: 0.7621\n"
     ]
    }
   ],
   "source": [
    "best_parameters = grid_search.best_params_\n",
    "\n",
    "# Get the best score achieved\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Get the best model itself, ready to be used\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# --- Print the results ---\n",
    "print(f\"Best Parameters Found:\\n{best_parameters}\")\n",
    "print(f\"\\nBest Adjusted Score: {best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "171b2ad7-ab90-45e6-b808-a32a2277fad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "63c83414-8690-43e6-98b5-3eded31d4aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 25)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f84c4816-f86c-4cd6-8e8e-68b71ddf9ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.        ,  0.        , 34.5       , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 3.        ,  1.        , 47.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 2.        ,  0.        , 62.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 3.        ,  0.        , 38.5       , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 3.        ,  0.        , 29.35980732, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 3.        ,  0.        ,  9.97990846, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d212ac92-8458-4165-be28-5f9914faf62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predictions = best_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8b390d59-669e-4d83-a6fd-0dad0f62fa14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Titel</th>\n",
       "      <th>col_0</th>\n",
       "      <th>...</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>col_10</th>\n",
       "      <th>col_11</th>\n",
       "      <th>col_12</th>\n",
       "      <th>col_13</th>\n",
       "      <th>col_14</th>\n",
       "      <th>col_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.188856</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.990834</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.155803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.196630</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.169054</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age  SibSp  Parch      Fare  Cabin  Embarked  Titel  \\\n",
       "0       3.0  0.0  22.000000    1.0    0.0  2.110213    8.0       2.0    2.0   \n",
       "1       1.0  1.0  38.000000    1.0    0.0  4.280593    2.0       0.0    3.0   \n",
       "2       3.0  1.0  26.000000    0.0    0.0  2.188856    8.0       2.0    1.0   \n",
       "3       1.0  1.0  35.000000    1.0    0.0  3.990834    2.0       2.0    3.0   \n",
       "4       3.0  0.0  35.000000    0.0    0.0  2.202765    8.0       2.0    2.0   \n",
       "..      ...  ...        ...    ...    ...       ...    ...       ...    ...   \n",
       "886     2.0  0.0  27.000000    0.0    0.0  2.639057    8.0       2.0    4.0   \n",
       "887     1.0  1.0  19.000000    0.0    0.0  3.433987    1.0       2.0    1.0   \n",
       "888     3.0  1.0  15.155803    1.0    2.0  3.196630    8.0       2.0    1.0   \n",
       "889     1.0  0.0  26.000000    0.0    0.0  3.433987    2.0       0.0    2.0   \n",
       "890     3.0  0.0  32.000000    0.0    0.0  2.169054    8.0       1.0    2.0   \n",
       "\n",
       "     col_0  ...  col_6  col_7  col_8  col_9  col_10  col_11  col_12  col_13  \\\n",
       "0        0  ...      0      0      0      0       1       0       0       0   \n",
       "1        0  ...      0      0      0      0       0       0       0       0   \n",
       "2        0  ...      0      0      0      0       0       0       0       0   \n",
       "3        0  ...      0      1      0      0       0       0       0       0   \n",
       "4        0  ...      0      0      0      0       0       0       1       0   \n",
       "..     ...  ...    ...    ...    ...    ...     ...     ...     ...     ...   \n",
       "886      0  ...      0      0      0      0       0       0       0       0   \n",
       "887      0  ...      0      0      0      0       0       0       0       0   \n",
       "888      0  ...      0      0      0      1       0       0       0       0   \n",
       "889      0  ...      0      0      0      0       0       0       1       0   \n",
       "890      0  ...      0      0      0      0       1       0       0       0   \n",
       "\n",
       "     col_14  col_15  \n",
       "0         0       0  \n",
       "1         0       1  \n",
       "2         0       0  \n",
       "3         0       0  \n",
       "4         0       0  \n",
       "..      ...     ...  \n",
       "886       1       0  \n",
       "887       0       0  \n",
       "888       0       0  \n",
       "889       0       0  \n",
       "890       0       0  \n",
       "\n",
       "[891 rows x 25 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "799c44cd-0967-48d3-b545-cbef5e436f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "  from sklearn.model_selection import train_test_split\n",
    "  from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f359c8e1-259a-4164-a26f-7cfcee93137e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GridSearchCV...\n",
      "Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n",
      "\n",
      "âœ… Tuning Complete!\n",
      "Best Parameters Found: {'estimator__max_depth': 1, 'learning_rate': 0.005, 'n_estimators': 50}\n",
      "Best Adjusted F1 Score (optimized by GridSearchCV): 0.7054\n",
      "\n",
      "--- Detailed Evaluation of the Best Model ---\n",
      "\n",
      "Cross-Validation Results for Best Model:\n",
      "  ACCURACY:\n",
      "    Train: 0.7868 (+/- 0.0034)\n",
      "    Test:  0.7867 (+/- 0.0304)\n",
      "    Overfitting Gap: 0.0001\n",
      "-------------------------\n",
      "  F1:\n",
      "    Train: 0.7103 (+/- 0.0060)\n",
      "    Test:  0.7075 (+/- 0.0545)\n",
      "    Overfitting Gap: 0.0028\n",
      "-------------------------\n",
      "  ROC_AUC:\n",
      "    Train: 0.7669 (+/- 0.0044)\n",
      "    Test:  0.7667 (+/- 0.0396)\n",
      "    Overfitting Gap: 0.0002\n",
      "-------------------------\n",
      "  PRECISION:\n",
      "    Train: 0.7421 (+/- 0.0045)\n",
      "    Test:  0.7433 (+/- 0.0406)\n",
      "    Overfitting Gap: -0.0012\n",
      "-------------------------\n",
      "  RECALL:\n",
      "    Train: 0.6813 (+/- 0.0098)\n",
      "    Test:  0.6808 (+/- 0.0878)\n",
      "    Overfitting Gap: 0.0004\n",
      "-------------------------\n",
      "\n",
      "--- Predictions on a Held-Out Test Set (from best_model) ---\n",
      "Unique predictions on test set: (array([0, 1], dtype=int64), array([118,  61], dtype=int64))\n",
      "\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82       110\n",
      "           1       0.74      0.65      0.69        69\n",
      "\n",
      "    accuracy                           0.78       179\n",
      "   macro avg       0.77      0.75      0.76       179\n",
      "weighted avg       0.77      0.78      0.77       179\n",
      "\n",
      "\n",
      "Confusion Matrix on Test Set:\n",
      "[[94 16]\n",
      " [24 45]]\n"
     ]
    }
   ],
   "source": [
    "def adjusted_scorer_func(estimator, X, y):\n",
    "    overfitting_penalty = 0.1\n",
    "    results = cross_validate(\n",
    "        estimator, X, y,\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        scoring=['accuracy', 'f1', 'roc_auc', 'precision', 'recall'],\n",
    "        return_train_score=True\n",
    "    )\n",
    "    cv_f1 = np.mean(results['test_f1'])\n",
    "    train_f1 = np.mean(results['train_f1'])\n",
    "    overfitting_gap = train_f1 - cv_f1\n",
    "    adjusted_score = cv_f1 - (overfitting_penalty * overfitting_gap)\n",
    "    return adjusted_score\n",
    "\n",
    "# --- 2. Run GridSearchCV by passing the function directly ---\n",
    "# Use the X_processed and y derived from your actual df\n",
    "ada = AdaBoostClassifier(estimator=DecisionTreeClassifier(random_state=42), random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 75, 100, 125, 150, 175, 200, 250, 300, 400], # Expanded range\n",
    "    'learning_rate': [0.005, 0.01, 0.02, 0.05, 0.1, 0.15, 0.2, 0.3], # Expanded range\n",
    "    'estimator__max_depth': [1, 2, 3, 4, 5, 6] \n",
    "}\n",
    "\n",
    "print(\"Starting GridSearchCV...\")\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ada,\n",
    "    param_grid=param_grid,\n",
    "    scoring=adjusted_scorer_func,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV with your REAL, PREPROCESSED DATA\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# --- 3. Analyze the results from GridSearchCV ---\n",
    "print(\"\\nâœ… Tuning Complete!\")\n",
    "print(f\"Best Parameters Found: {grid_search.best_params_}\")\n",
    "print(f\"Best Adjusted F1 Score (optimized by GridSearchCV): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# --- 4. Perform a final, detailed evaluation of the BEST MODEL ---\n",
    "print(\"\\n--- Detailed Evaluation of the Best Model ---\")\n",
    "metrics_to_evaluate = ['accuracy', 'f1', 'roc_auc', 'precision', 'recall']\n",
    "\n",
    "final_cv_results = cross_validate(\n",
    "    best_model, X, y, # Use X_processed and y from your actual data\n",
    "    cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42),\n",
    "    scoring=metrics_to_evaluate,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nCross-Validation Results for Best Model:\")\n",
    "for metric in metrics_to_evaluate:\n",
    "    test_scores = final_cv_results[f'test_{metric}']\n",
    "    train_scores = final_cv_results[f'train_{metric}']\n",
    "    print(f\"  {metric.upper()}:\")\n",
    "    print(f\"    Train: {np.mean(train_scores):.4f} (+/- {np.std(train_scores):.4f})\")\n",
    "    print(f\"    Test:  {np.mean(test_scores):.4f} (+/- {np.std(test_scores):.4f})\")\n",
    "    print(f\"    Overfitting Gap: {(np.mean(train_scores) - np.mean(test_scores)):.4f}\")\n",
    "    print(\"-\" * 25)\n",
    "\n",
    "# --- 5. Make predictions and print a Classification Report on a held-out test set ---\n",
    "# Split your REAL, PREPROCESSED DATA for a final, unseen test\n",
    "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\n--- Predictions on a Held-Out Test Set (from best_model) ---\")\n",
    "test_preds = best_model.predict(X_test_final)\n",
    "\n",
    "print(f\"Unique predictions on test set: {np.unique(test_preds, return_counts=True)}\")\n",
    "print(\"\\nClassification Report on Test Set:\")\n",
    "print(classification_report(y_test_final, test_preds))\n",
    "print(\"\\nConfusion Matrix on Test Set:\")\n",
    "print(confusion_matrix(y_test_final, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a098fd4a-7a61-4061-90c0-05ee9a72917a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
