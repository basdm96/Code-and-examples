{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f187bb-09c0-4a74-a1ca-d2649a4e7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_validate\n",
    "df = pd.read_csv(r\"C:\\Users\\basde\\OneDrive\\Documenten\\GitHub\\Titanic\\train.csv\")\n",
    "y = df[\"Survived\"]\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "df = df.select_dtypes(include=['number'])\n",
    "df = df.drop(['PassengerId','Survived'], axis=1)\n",
    "# 1. **Imports** are done above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4068ca8-4d53-4cd6-a836-6e3b08d40f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline Evaluation...\n",
      "Running Technique Evaluations...\n",
      "  - Evaluating: Log(1+x) Transformation\n",
      "  - Evaluating: Square Root Transformation\n",
      "  - Evaluating: Winsorization (5%-95%)\n",
      "Running Feature Dropped Evaluation...\n",
      "\n",
      "--- Evaluation Results ---\n",
      "                            Mean Train Score  Mean CV Score  Std CV Score\n",
      "Log(1+x) Transformation             0.797698       0.795719      0.021923\n",
      "Baseline                            0.796578       0.793472      0.023554\n",
      "Feature Dropped                     0.793488       0.791218      0.028467\n",
      "Square Root Transformation          0.799102       0.788984      0.025405\n",
      "Winsorization (5%-95%)              0.798260       0.787860      0.024349\n"
     ]
    }
   ],
   "source": [
    "# 2. **Setup**\n",
    "\n",
    "# a. Define columns to process\n",
    "columns_to_process = ['Fare']\n",
    "\n",
    "# b. Define cross-validation strategy\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# c. Define the evaluation model\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# d. Define a dictionary of techniques\n",
    "# First, create a custom transformer for Winsorization\n",
    "class Winsorizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer to apply Winsorization to a column.\n",
    "    It caps and floors the data at specified quantiles.\n",
    "    \"\"\"\n",
    "    def __init__(self, limits=(0.05, 0.05)):\n",
    "        self.limits = limits\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # The input X from a ColumnTransformer can be a DataFrame.\n",
    "        # We convert it to a 1D array for winsorize, then reshape back.\n",
    "        x_transformed = winsorize(X[:, 0], limits=self.limits)\n",
    "        return x_transformed.reshape(-1, 1)\n",
    "\n",
    "# Define the dictionary of techniques to test\n",
    "techniques = {\n",
    "    'Log(1+x) Transformation': FunctionTransformer(np.log1p),\n",
    "    'Square Root Transformation': FunctionTransformer(np.sqrt),\n",
    "    'Winsorization (5%-95%)': Winsorizer(limits=(0.05, 0.05))\n",
    "}\n",
    "\n",
    "# 3. **Execution and Evaluation**\n",
    "\n",
    "# a. Create an empty dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Identify numeric columns for imputation purposes\n",
    "numeric_features = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "\n",
    "# b. Baseline Evaluation\n",
    "print(\"Running Baseline Evaluation...\")\n",
    "# Create a pipeline that first imputes missing values (with the median)\n",
    "# and then fits the logistic regression model.\n",
    "baseline_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Perform cross-validation, returning train scores\n",
    "baseline_scores_dict = cross_validate(\n",
    "    baseline_pipeline, df, y, cv=cv, scoring='accuracy', return_train_score=True\n",
    ")\n",
    "\n",
    "# Store the mean and standard deviation of the scores\n",
    "results['Baseline'] = {\n",
    "    'Mean Train Score': baseline_scores_dict['train_score'].mean(),\n",
    "    'Mean CV Score': baseline_scores_dict['test_score'].mean(),\n",
    "    'Std CV Score': baseline_scores_dict['test_score'].std()\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# c. Technique Evaluation Loop\n",
    "print(\"Running Technique Evaluations...\")\n",
    "# Find the numerical index of the column to be transformed\n",
    "fare_index = [i for i, col in enumerate(numeric_features) if col in columns_to_process][0]\n",
    "\n",
    "for name, transformer in techniques.items():\n",
    "    print(f\"  - Evaluating: {name}\")\n",
    "    \n",
    "    # Define a preprocessor pipeline with sequential, non-nested steps\n",
    "    preprocessor = Pipeline(steps=[\n",
    "        ('imputer', ColumnTransformer(\n",
    "            transformers=[('numeric_imputer', SimpleImputer(strategy='median'), numeric_features)],\n",
    "            remainder='passthrough'\n",
    "        )),\n",
    "        ('transform', ColumnTransformer(\n",
    "            transformers=[('apply_technique', transformer, [fare_index])],\n",
    "            remainder='passthrough'\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Create the main pipeline\n",
    "    main_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Perform cross-validation, returning train scores\n",
    "    scores_dict = cross_validate(\n",
    "        main_pipeline, df, y, cv=cv, scoring='accuracy', return_train_score=True\n",
    "    )\n",
    "    \n",
    "    # Store the results\n",
    "    results[name] = {\n",
    "        'Mean Train Score': scores_dict['train_score'].mean(),\n",
    "        'Mean CV Score': scores_dict['test_score'].mean(),\n",
    "        'Std CV Score': scores_dict['test_score'].std()\n",
    "    }\n",
    "\n",
    "\n",
    "# d. Feature Dropped Evaluation\n",
    "print(\"Running Feature Dropped Evaluation...\")\n",
    "# Create a new DataFrame without the 'Fare' column\n",
    "df_dropped = df.drop(columns=columns_to_process)\n",
    "\n",
    "dropped_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Perform cross-validation, returning train scores\n",
    "dropped_scores_dict = cross_validate(\n",
    "    dropped_pipeline, df_dropped, y, cv=cv, scoring='accuracy', return_train_score=True\n",
    ")\n",
    "\n",
    "# Store the results\n",
    "results['Feature Dropped'] = {\n",
    "    'Mean Train Score': dropped_scores_dict['train_score'].mean(),\n",
    "    'Mean CV Score': dropped_scores_dict['test_score'].mean(),\n",
    "    'Std CV Score': dropped_scores_dict['test_score'].std()\n",
    "}\n",
    "# 4. Conclusion\n",
    "print(\"\\n--- Evaluation Results ---\")\n",
    "# Convert the results dictionary to a pandas DataFrame\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "\n",
    "# Define column order for clarity and select them\n",
    "column_order = ['Mean Train Score', 'Mean CV Score', 'Std CV Score']\n",
    "results_df = results_df[column_order]\n",
    "\n",
    "# Sort the results by the mean cross-validation score in descending order\n",
    "results_df = results_df.sort_values(by='Mean CV Score', ascending=False)\n",
    "\n",
    "# Print the final comparison table\n",
    "print(results_df.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fa4a2e8-8b18-4b3e-b624-359cab741eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21150023-1d39-440e-b170-ca7f27cdc9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
