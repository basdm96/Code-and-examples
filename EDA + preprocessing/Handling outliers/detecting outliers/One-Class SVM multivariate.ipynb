{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aaf09e8-ea51-4ba0-9c08-bed5cb442447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f18d188-099f-402b-8cd5-9a5fc2cb731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- One-Class SVM Method for Outlier Detection ---\n",
    "\n",
    "# When to use this method:\n",
    "# - For high-dimensional data.\n",
    "# - When you want to define a \"boundary\" around normal data points.\n",
    "# - It's effective for \"novelty detection\" (identifying new, unseen patterns).\n",
    "# Note: One-Class SVM can be sensitive to outliers and often requires data scaling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211a6b65-6e24-4315-98c5-a2b451ea5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and Scale the Data\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "data_feature = df['MedInc'].values.reshape(-1, 1)\n",
    "\n",
    "# Scaling is important for SVM algorithms\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data_feature)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89641ed-9638-4535-92cd-8fcd5281f068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e666b60-eaf1-45ac-8ed6-8b6576b7990c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running hyperparameter tuning for One-Class SVM...\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Hyperparameter Tuning ---\n",
    "# We will test different combinations of hyperparameters.\n",
    "# nu: Think of this as being very similar to the contamination parameter in the other models. It's a number between 0 and 1 that gives the model an idea of what percentage of your data you expect to be outliers.\n",
    "\n",
    "#     A small nu (e.g., 0.01) tells the model to be very strict and assume very few points are outliers.\n",
    "\n",
    "#     A larger nu (e.g., 0.1) tells the model to be more lenient and allows it to flag a larger fraction of the data as outliers.\n",
    "\n",
    "# gamma: This parameter controls the \"reach\" or influence of a single data point. It only applies when using the rbf kernel (which is the most common).\n",
    "\n",
    "#     'scale' (default and recommended): The influence is calculated automatically based on the variance of your data. This is usually the best choice.\n",
    "\n",
    "#     'auto': The influence is 1 / n_features.\n",
    "\n",
    "#     A small gamma value (e.g., 0.01): A single point has a far-reaching influence, leading to a smoother, more general boundary around the normal data.\n",
    "\n",
    "#     A large gamma value (e.g., 10): A single point has a very local influence, which can create a more complex, \"tighter\" boundary that might overfit to the training data.\n",
    "# Define the grid of parameters to test for One-Class SVM\n",
    "param_grid = {\n",
    "    'nu': [0.01, 0.05, 0.1],\n",
    "    'gamma': ['scale', 'auto', 0.1]\n",
    "}\n",
    "\n",
    "# Store the results\n",
    "tuning_results = []\n",
    "\n",
    "print(\"Running hyperparameter tuning for One-Class SVM...\")\n",
    "for nu_val in param_grid['nu']:\n",
    "    for gamma_val in param_grid['gamma']:\n",
    "        # Create and fit the model with the current parameters\n",
    "        svm = OneClassSVM(nu=nu_val, kernel='rbf', gamma=gamma_val)\n",
    "        \n",
    "        # Fit the model and get predictions\n",
    "        predictions = svm.fit_predict(data)\n",
    "        \n",
    "        # Count the number of outliers (-1)\n",
    "        num_outliers = np.sum(predictions == -1)\n",
    "        \n",
    "        # Store the results\n",
    "        tuning_results.append({\n",
    "            'nu': nu_val,\n",
    "            'gamma': gamma_val,\n",
    "            'num_outliers': num_outliers\n",
    "        })\n",
    "\n",
    "# Convert results to a DataFrame for easy viewing\n",
    "results_df = pd.DataFrame(tuning_results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4126c736-abc3-4016-89fd-002f6bb4150a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning complete. Here are the results:\n",
      "     nu  gamma  num_outliers\n",
      "0  0.01  scale           380\n",
      "1  0.01   auto           380\n",
      "2  0.01    0.1           203\n",
      "3  0.05  scale          1116\n",
      "4  0.05   auto          1116\n",
      "5  0.05    0.1          1033\n",
      "6  0.10  scale          2078\n",
      "7  0.10   auto          2078\n",
      "8  0.10    0.1          2064\n",
      "\n",
      "--- Interpretation ---\n",
      "Analyze this table to choose the best parameters. For this example, we'll proceed with nu=0.05 and gamma='scale'.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Display Tuning Results ---\n",
    "print(\"\\nTuning complete. Here are the results:\")\n",
    "print(results_df)\n",
    "print(\"\\n--- Interpretation ---\")\n",
    "print(\"Analyze this table to choose the best parameters. For this example, we'll proceed with nu=0.05 and gamma='scale'.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e7a0044-d2c8-4c15-a099-ca5b9eb153cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Apply the Final Model ---\n",
    "# Based on the tuning results, we select our final parameters.\n",
    "best_nu = 0.05\n",
    "best_gamma = 'scale'\n",
    "\n",
    "# Create and fit the final model\n",
    "final_svm = OneClassSVM(nu=best_nu, kernel='rbf', gamma=best_gamma)\n",
    "predictions = final_svm.fit_predict(data)\n",
    "\n",
    "# Get the indices of the outliers\n",
    "outlier_indices = np.where(predictions == -1)[0]\n",
    "\n",
    "# Get the outlier scores (the lower, the more abnormal)\n",
    "outlier_scores = final_svm.decision_function(data)[outlier_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84fe717e-ad07-4cca-b7d2-6e2d2fcca2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create a DataFrame of the outliers\n",
    "outliers_df = df.loc[outlier_indices].copy()\n",
    "outliers_df['SVM_Score'] = outlier_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be10ab5b-8e84-470c-b31a-1cca55ea68a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Applying Final Model (nu=0.05, gamma='scale') ---\n",
      "Found 1116 outliers.\n",
      "\n",
      "DataFrame containing the identified outliers (first 5 rows):\n",
      "    MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0   8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1   8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "11  3.2705      52.0  4.772480   1.024523      1504.0  2.049046     37.85   \n",
      "42  1.0250      49.0  3.772487   1.068783       462.0  2.444444     37.84   \n",
      "48  0.9506      40.0  3.900000   1.218750       423.0  2.643750     37.82   \n",
      "\n",
      "    Longitude  SVM_Score  \n",
      "0     -122.23  -0.029071  \n",
      "1     -122.22  -0.026198  \n",
      "11    -122.26  -0.000253  \n",
      "42    -122.26  -1.328459  \n",
      "48    -122.26  -3.898390  \n"
     ]
    }
   ],
   "source": [
    "# --- 6. Display Final Outliers ---\n",
    "print(f\"\\n--- Applying Final Model (nu={best_nu}, gamma='{best_gamma}') ---\")\n",
    "print(f\"Found {len(outliers_df)} outliers.\")\n",
    "print(\"\\nDataFrame containing the identified outliers (first 5 rows):\")\n",
    "print(outliers_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54d8d7f0-3448-4f16-823e-96f4b76ff1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -0.029071\n",
       "1       -0.026198\n",
       "11      -0.000253\n",
       "42      -1.328459\n",
       "48      -3.898390\n",
       "           ...   \n",
       "20465   -0.000469\n",
       "20495   -0.000085\n",
       "20503   -0.022914\n",
       "20537   -0.152227\n",
       "20592   -6.160399\n",
       "Name: SVM_Score, Length: 1116, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_df['SVM_Score']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
