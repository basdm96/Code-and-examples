{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a83ca33-c4af-44d0-bfc1-2e77018dc26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4778aecf-73cb-4404-8cdc-01041192801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classification dataset\n",
    "dft = pd.read_csv(r\"C:\\Users\\basde\\Documents\\GitHub\\Code-and-examples\\Projects\\Binary Classification with a Bank Dataset\\train.csv\")\n",
    "dfo = pd.read_csv(r\"C:\\Users\\basde\\Documents\\GitHub\\Code-and-examples\\Projects\\Binary Classification with a Bank Dataset\\bank-full.csv\", delimiter=';')\n",
    "dfo['y'] = dfo['y'].map({'no' : 0, 'yes': 1})\n",
    "# df = pd.concat([dft, dfo])\n",
    "y = dfo['y']\n",
    "dfo = dfo.drop('y', axis=1)\n",
    "dfo = dfo.drop(['month', 'day', 'job','marital'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e0e6daf-4a4b-4ea6-81e8-fede0d104152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education\n",
       "secondary    23202\n",
       "tertiary     13301\n",
       "primary       6851\n",
       "unknown       1857\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfo['education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80419a82-90ce-450f-ab82-5505c7767502",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo['default'] = pd.get_dummies(dfo['default'], drop_first=True, dtype=int)\n",
    "dfo['housing'] = pd.get_dummies(dfo['housing'], drop_first=True, dtype=int)\n",
    "dfo['loan'] = pd.get_dummies(dfo['loan'], drop_first=True, dtype=int)\n",
    "dfo['poutcome'] = dfo['poutcome'].map({'failure': 0, 'other': 0, 'unknown': 0, 'success': 1})\n",
    "category_order = ['primary', 'secondary', 'unknown', 'tertiary']\n",
    "ordinal_encoder = OrdinalEncoder(categories=[category_order])\n",
    "dfo['education'] = ordinal_encoder.fit_transform(dfo[['education']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32a57e6f-9253-45da-9061-3aff95b21f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfo.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29e4e136-5974-4ba6-985c-335623f2133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import set_config\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "set_config(transform_output=\"pandas\")\n",
    "# Custom transformer for manual mapping of categorical values\n",
    "class ColumnValueMapper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Applies a specified mapping to a column.\n",
    "    Values not in the mapping are left unchanged.\n",
    "    \"\"\"\n",
    "    def __init__(self, mapping):\n",
    "        self.mapping = mapping\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_out = X.copy()\n",
    "        # Get the first (and only) column name to apply the mapping\n",
    "        col_name = X_out.columns[0]\n",
    "        X_out[col_name] = X_out[col_name].replace(self.mapping)\n",
    "        return X_out\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return input_features\n",
    "\n",
    "# a. Specify the feature to apply transformations on\n",
    "feature_to_transform = 'contact'\n",
    "\n",
    "# b. Define the classification models to evaluate\n",
    "models = {\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(random_state=42, verbose=0)\n",
    "}\n",
    "\n",
    "# c. Define the transformation pipelines to test on the specified feature\n",
    "transformation_pipelines = {\n",
    "    'OneHotEncoder': ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('encoder', Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False))\n",
    "            ]), [feature_to_transform])\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    ),\n",
    "    'OrdinalEncoder': ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('encoder', Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "            ]), [feature_to_transform])\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    ),\n",
    "    'ManualMap_OneHotEncoder': ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('encoder', Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                ('mapper', ColumnValueMapper(mapping={'telephone': 'cellular'})),\n",
    "                ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False))\n",
    "            ]), [feature_to_transform])\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "}\n",
    "\n",
    "# d. Define the classification scoring metrics\n",
    "scoring_metrics = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_score': 'f1_weighted',\n",
    "    'precision': 'precision_weighted',\n",
    "    'recall': 'recall_weighted'\n",
    "}\n",
    "\n",
    "# e. Define the cross-validation strategy\n",
    "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c293cf4-e09f-4180-b5a0-cd919777ce60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating Model: XGBoost ---\n",
      "--- feature dropped: XGBoost ---\n",
      "--- tranformation: OneHotEncoder ---\n",
      "--- tranformation: OrdinalEncoder ---\n",
      "--- tranformation: ManualMap_OneHotEncoder ---\n",
      "--- Evaluating Model: LightGBM ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 925\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 926\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 924\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 924\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 926\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- feature dropped: LightGBM ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 928\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 928\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- tranformation: OneHotEncoder ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 928\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 927\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004000 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 927\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 929\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- tranformation: OrdinalEncoder ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 927\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 928\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 926\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 926\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 928\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- tranformation: ManualMap_OneHotEncoder ---\n",
      "--- Evaluating Model: CatBoost ---\n",
      "--- feature dropped: CatBoost ---\n",
      "--- tranformation: OneHotEncoder ---\n",
      "--- tranformation: OrdinalEncoder ---\n",
      "--- tranformation: ManualMap_OneHotEncoder ---\n"
     ]
    }
   ],
   "source": [
    "# This DataFrame will hold all results for final comparison\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "# --- Main Loop ---\n",
    "for model_name, model in models.items():\n",
    "    print(f\"--- Evaluating Model: {model_name} ---\")\n",
    "    model_results = {}\n",
    "\n",
    "    # a. \"Feature Dropped\" Evaluation\n",
    "    # Dynamically drops the feature specified in cell 3\n",
    "    X_dropped = X.drop(columns=[feature_to_transform])\n",
    "    feature_dropped_scores = cross_validate(\n",
    "        model, X_dropped, y, cv=cv_strategy,\n",
    "        scoring=scoring_metrics, return_train_score=True\n",
    "    )\n",
    "    model_results['Feature Dropped'] = {\n",
    "        'Train F1-Score': feature_dropped_scores['train_f1_score'].mean(),\n",
    "        'CV F1-Score': feature_dropped_scores['test_f1_score'].mean(),\n",
    "        'CV Accuracy': feature_dropped_scores['test_accuracy'].mean()\n",
    "    }\n",
    "    print(f\"--- feature dropped: {model_name} ---\")\n",
    "    # # b. \"Imputation Only\" Baseline Evaluation\n",
    "    # # Applies imputation only to the specified feature, others are passed through\n",
    "    # baseline_preprocessor = ColumnTransformer(\n",
    "    #     transformers=[\n",
    "    #         ('imputer', SimpleImputer(strategy='median'), [feature_to_transform])\n",
    "    #     ],\n",
    "    #     remainder='passthrough'\n",
    "    # )\n",
    "    # baseline_pipeline = Pipeline(steps=[\n",
    "    #     ('preprocessor', baseline_preprocessor),\n",
    "    #     ('model', model)\n",
    "    # ])\n",
    "    # baseline_scores = cross_validate(\n",
    "    #     baseline_pipeline, X, y, cv=cv_strategy,\n",
    "    #     scoring=scoring_metrics, return_train_score=True\n",
    "    # )\n",
    "    # model_results['Baseline (Imputation Only)'] = {\n",
    "    #     'Train F1-Score': baseline_scores['train_f1_score'].mean(),\n",
    "    #     'CV F1-Score': baseline_scores['test_f1_score'].mean(),\n",
    "    #     'CV Accuracy': baseline_scores['test_accuracy'].mean()\n",
    "    # }\n",
    "    # print(f\"--- imputation only: {model_name} ---\")\n",
    "    # c. Transformation Pipelines Evaluation\n",
    "    # Iterates through the ColumnTransformer pipelines defined in cell 3\n",
    "    for tech_name, preprocessor in transformation_pipelines.items():\n",
    "        full_pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        scores = cross_validate(\n",
    "            full_pipeline, X, y, cv=cv_strategy,\n",
    "            scoring=scoring_metrics, return_train_score=True\n",
    "        )\n",
    "        model_results[tech_name] = {\n",
    "            'Train F1-Score': scores['train_f1_score'].mean(),\n",
    "            'CV F1-Score': scores['test_f1_score'].mean(),\n",
    "            'CV Accuracy': scores['test_accuracy'].mean()\n",
    "        }\n",
    "        print(f\"--- tranformation: {tech_name} ---\")\n",
    "    # d. Consolidate and store results\n",
    "    temp_df = pd.DataFrame.from_dict(model_results, orient='index')\n",
    "    temp_df['Model'] = model_name\n",
    "    all_results = pd.concat([all_results, temp_df])\n",
    "\n",
    "# e. Final processing for the results table\n",
    "all_results.reset_index(inplace=True)\n",
    "all_results.rename(columns={'index': 'Preprocessing Technique'}, inplace=True)\n",
    "all_results['Generalization'] = all_results['CV F1-Score'] / all_results['Train F1-Score']\n",
    "all_results = all_results.sort_values(by='CV F1-Score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "488e7202-c308-46ad-8035-3a282447c830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing Technique</th>\n",
       "      <th>CV F1-Score</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>Train F1-Score</th>\n",
       "      <th>Generalization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>OrdinalEncoder</td>\n",
       "      <td>0.893530</td>\n",
       "      <td>0.902856</td>\n",
       "      <td>0.911901</td>\n",
       "      <td>0.979854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>ManualMap_OneHotEncoder</td>\n",
       "      <td>0.893398</td>\n",
       "      <td>0.902856</td>\n",
       "      <td>0.912014</td>\n",
       "      <td>0.979588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>OneHotEncoder</td>\n",
       "      <td>0.892760</td>\n",
       "      <td>0.902325</td>\n",
       "      <td>0.912347</td>\n",
       "      <td>0.978531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Feature Dropped</td>\n",
       "      <td>0.892059</td>\n",
       "      <td>0.901949</td>\n",
       "      <td>0.910577</td>\n",
       "      <td>0.979664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>OrdinalEncoder</td>\n",
       "      <td>0.891153</td>\n",
       "      <td>0.901086</td>\n",
       "      <td>0.923675</td>\n",
       "      <td>0.964791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>ManualMap_OneHotEncoder</td>\n",
       "      <td>0.891141</td>\n",
       "      <td>0.901219</td>\n",
       "      <td>0.923216</td>\n",
       "      <td>0.965257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>OneHotEncoder</td>\n",
       "      <td>0.891027</td>\n",
       "      <td>0.900135</td>\n",
       "      <td>0.930316</td>\n",
       "      <td>0.957768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>OneHotEncoder</td>\n",
       "      <td>0.890857</td>\n",
       "      <td>0.901108</td>\n",
       "      <td>0.923938</td>\n",
       "      <td>0.964196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>ManualMap_OneHotEncoder</td>\n",
       "      <td>0.890768</td>\n",
       "      <td>0.900201</td>\n",
       "      <td>0.930671</td>\n",
       "      <td>0.957124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>OrdinalEncoder</td>\n",
       "      <td>0.890396</td>\n",
       "      <td>0.899516</td>\n",
       "      <td>0.931357</td>\n",
       "      <td>0.956021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>Feature Dropped</td>\n",
       "      <td>0.889563</td>\n",
       "      <td>0.900157</td>\n",
       "      <td>0.922053</td>\n",
       "      <td>0.964764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Feature Dropped</td>\n",
       "      <td>0.887964</td>\n",
       "      <td>0.898100</td>\n",
       "      <td>0.930188</td>\n",
       "      <td>0.954607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Preprocessing Technique  CV F1-Score  CV Accuracy  \\\n",
       "6   LightGBM           OrdinalEncoder     0.893530     0.902856   \n",
       "7   LightGBM  ManualMap_OneHotEncoder     0.893398     0.902856   \n",
       "5   LightGBM            OneHotEncoder     0.892760     0.902325   \n",
       "4   LightGBM          Feature Dropped     0.892059     0.901949   \n",
       "10  CatBoost           OrdinalEncoder     0.891153     0.901086   \n",
       "11  CatBoost  ManualMap_OneHotEncoder     0.891141     0.901219   \n",
       "1    XGBoost            OneHotEncoder     0.891027     0.900135   \n",
       "9   CatBoost            OneHotEncoder     0.890857     0.901108   \n",
       "3    XGBoost  ManualMap_OneHotEncoder     0.890768     0.900201   \n",
       "2    XGBoost           OrdinalEncoder     0.890396     0.899516   \n",
       "8   CatBoost          Feature Dropped     0.889563     0.900157   \n",
       "0    XGBoost          Feature Dropped     0.887964     0.898100   \n",
       "\n",
       "    Train F1-Score  Generalization  \n",
       "6         0.911901        0.979854  \n",
       "7         0.912014        0.979588  \n",
       "5         0.912347        0.978531  \n",
       "4         0.910577        0.979664  \n",
       "10        0.923675        0.964791  \n",
       "11        0.923216        0.965257  \n",
       "1         0.930316        0.957768  \n",
       "9         0.923938        0.964196  \n",
       "3         0.930671        0.957124  \n",
       "2         0.931357        0.956021  \n",
       "8         0.922053        0.964764  \n",
       "0         0.930188        0.954607  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorder columns for a more logical presentation\n",
    "final_columns_order = [\n",
    "    'Model',\n",
    "    'Preprocessing Technique',\n",
    "    'CV F1-Score',\n",
    "    'CV Accuracy',\n",
    "    'Train F1-Score',\n",
    "    'Generalization'\n",
    "]\n",
    "all_results = all_results[final_columns_order]\n",
    "\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be208fa-ad43-40a2-9f48-6a245707584d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
