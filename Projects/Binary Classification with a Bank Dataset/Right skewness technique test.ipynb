{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66f187bb-09c0-4a74-a1ca-d2649a4e7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec006b2-3db4-4c56-8d61-f6edbac947f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8422ef35-f0a4-48ab-a025-e916d1b6ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.read_csv(r\"C:\\Users\\basde\\Documents\\GitHub\\Code-and-examples\\Projects\\Binary Classification with a Bank Dataset\\train.csv\")\n",
    "dfo = pd.read_csv(r\"C:\\Users\\basde\\Documents\\GitHub\\Code-and-examples\\Projects\\Binary Classification with a Bank Dataset\\bank-full.csv\", delimiter=';')\n",
    "dfo['y'] = dfo['y'].map({'no' : 0, 'yes': 1})\n",
    "df = pd.concat([dft, dfo])\n",
    "y = df['y']\n",
    "df = df.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e837a81-d897-4747-afc6-6534a99cbedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['default'] = pd.get_dummies(df['default'], drop_first=True, dtype=int)\n",
    "df['housing'] = pd.get_dummies(df['housing'], drop_first=True, dtype=int)\n",
    "df['loan'] = pd.get_dummies(df['loan'], drop_first=True, dtype=int)\n",
    "df['contact'] = df['contact'].map({'telephone': 'cellular', 'unknown' : 'unknown', 'telephone': 'telephone'})\n",
    "df['contact'] = pd.get_dummies(df['contact'], drop_first=True, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6754ad43-40d8-4706-b7f6-526b83342bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select_dtypes(include=['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0562aebb-3772-4a8e-a076-37d6bfb4e56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Baseline Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 2. **Setup**\n",
    "\n",
    "# a. Define columns to process\n",
    "columns_to_process = ['duration']\n",
    "\n",
    "# b. Define cross-validation strategy\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# c. Define the evaluation model\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# d. Define a dictionary of techniques\n",
    "# First, create a custom transformer for Winsorization\n",
    "class Winsorizer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer to apply Winsorization to a column.\n",
    "    It caps and floors the data at specified quantiles.\n",
    "    \"\"\"\n",
    "    def __init__(self, limits=(0, 0.05)):\n",
    "        self.limits = limits\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # The input X from a ColumnTransformer can be a DataFrame.\n",
    "        # We convert it to a 1D array for winsorize, then reshape back.\n",
    "        x_transformed = winsorize(X[:, 0], limits=self.limits)\n",
    "        return x_transformed.reshape(-1, 1)\n",
    "\n",
    "# Define the dictionary of techniques to test\n",
    "techniques = {\n",
    "    'Log(1+x) Transformation': FunctionTransformer(np.log1p),\n",
    "    'Square Root Transformation': FunctionTransformer(np.sqrt),\n",
    "    'Winsorization (5%-95%)': Winsorizer(limits=(0.05, 0.05))\n",
    "}\n",
    "\n",
    "# 3. **Execution and Evaluation**\n",
    "\n",
    "# a. Create an empty dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Identify numeric columns for imputation purposes\n",
    "numeric_features = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "\n",
    "# b. Baseline Evaluation\n",
    "print(\"Running Baseline Evaluation...\")\n",
    "# Create a pipeline that first imputes missing values (with the median)\n",
    "# and then fits the logistic regression model.\n",
    "baseline_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Perform cross-validation, returning train scores\n",
    "baseline_scores_dict = cross_validate(\n",
    "    baseline_pipeline, df, y, cv=cv, scoring='accuracy', return_train_score=True\n",
    ")\n",
    "\n",
    "# Store the mean and standard deviation of the scores\n",
    "results['Baseline'] = {\n",
    "    'Mean Train Score': baseline_scores_dict['train_score'].mean(),\n",
    "    'Mean CV Score': baseline_scores_dict['test_score'].mean(),\n",
    "    'Std CV Score': baseline_scores_dict['test_score'].std()\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# c. Technique Evaluation Loop\n",
    "print(\"Running Technique Evaluations...\")\n",
    "# Find the numerical index of the column to be transformed\n",
    "fare_index = [i for i, col in enumerate(numeric_features) if col in columns_to_process][0]\n",
    "\n",
    "for name, transformer in techniques.items():\n",
    "    print(f\"  - Evaluating: {name}\")\n",
    "    \n",
    "    # Define a preprocessor pipeline with sequential, non-nested steps\n",
    "    preprocessor = Pipeline(steps=[\n",
    "        ('imputer', ColumnTransformer(\n",
    "            transformers=[('numeric_imputer', SimpleImputer(strategy='median'), numeric_features)],\n",
    "            remainder='passthrough'\n",
    "        )),\n",
    "        ('transform', ColumnTransformer(\n",
    "            transformers=[('apply_technique', transformer, [fare_index])],\n",
    "            remainder='passthrough'\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Create the main pipeline\n",
    "    main_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Perform cross-validation, returning train scores\n",
    "    scores_dict = cross_validate(\n",
    "        main_pipeline, df, y, cv=cv, scoring='accuracy', return_train_score=True\n",
    "    )\n",
    "    \n",
    "    # Store the results\n",
    "    results[name] = {\n",
    "        'Mean Train Score': scores_dict['train_score'].mean(),\n",
    "        'Mean CV Score': scores_dict['test_score'].mean(),\n",
    "        'Std CV Score': scores_dict['test_score'].std()\n",
    "    }\n",
    "\n",
    "\n",
    "# d. Feature Dropped Evaluation\n",
    "print(\"Running Feature Dropped Evaluation...\")\n",
    "# Create a new DataFrame without the 'Fare' column\n",
    "df_dropped = df.drop(columns=columns_to_process)\n",
    "\n",
    "dropped_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Perform cross-validation, returning train scores\n",
    "dropped_scores_dict = cross_validate(\n",
    "    dropped_pipeline, df_dropped, y, cv=cv, scoring='accuracy', return_train_score=True\n",
    ")\n",
    "\n",
    "# Store the results\n",
    "results['Feature Dropped'] = {\n",
    "    'Mean Train Score': dropped_scores_dict['train_score'].mean(),\n",
    "    'Mean CV Score': dropped_scores_dict['test_score'].mean(),\n",
    "    'Std CV Score': dropped_scores_dict['test_score'].std()\n",
    "}\n",
    "# 4. Conclusion\n",
    "print(\"\\n--- Evaluation Results ---\")\n",
    "# Convert the results dictionary to a pandas DataFrame\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "\n",
    "# Define column order for clarity and select them\n",
    "column_order = ['Mean Train Score', 'Mean CV Score', 'Std CV Score']\n",
    "results_df = results_df[column_order]\n",
    "\n",
    "# Sort the results by the mean cross-validation score in descending order\n",
    "results_df = results_df.sort_values(by='Mean CV Score', ascending=False)\n",
    "\n",
    "# Print the final comparison table\n",
    "print(results_df.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa4a2e8-8b18-4b3e-b624-359cab741eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21150023-1d39-440e-b170-ca7f27cdc9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
