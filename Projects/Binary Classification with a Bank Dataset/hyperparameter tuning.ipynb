{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68491c94-3ead-4fb2-9e48-d277b66d6a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6933996a-506f-4924-b39d-90d084333036",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.read_csv(r\"C:\\Users\\basde\\Documents\\GitHub\\Code-and-examples\\Projects\\Binary Classification with a Bank Dataset\\train.csv\")\n",
    "dfo = pd.read_csv(r\"C:\\Users\\basde\\Documents\\GitHub\\Code-and-examples\\Projects\\Binary Classification with a Bank Dataset\\bank-full.csv\", delimiter=';')\n",
    "dfo['y'] = dfo['y'].map({'no' : 0, 'yes': 1})\n",
    "# df = pd.concat([dft, dfo])\n",
    "y = dfo['y']\n",
    "dfo = dfo.drop('y', axis=1)\n",
    "dfo = dfo.drop(['month', 'day'], axis=1)\n",
    "dfo['feature'] = dfo['duration'] * dfo['campaign'] * dfo['pdays']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce78308d-7ac6-4c5d-ada9-9bc0af256372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 15 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   duration   45211 non-null  int64 \n",
      " 10  campaign   45211 non-null  int64 \n",
      " 11  pdays      45211 non-null  int64 \n",
      " 12  previous   45211 non-null  int64 \n",
      " 13  poutcome   45211 non-null  object\n",
      " 14  feature    45211 non-null  int64 \n",
      "dtypes: int64(7), object(8)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dfo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03a7815f-8f84-418b-8a64-469724a29f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 15 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   age        45211 non-null  int64   \n",
      " 1   job        45211 non-null  category\n",
      " 2   marital    45211 non-null  category\n",
      " 3   education  45211 non-null  category\n",
      " 4   default    45211 non-null  category\n",
      " 5   balance    45211 non-null  int64   \n",
      " 6   housing    45211 non-null  category\n",
      " 7   loan       45211 non-null  category\n",
      " 8   contact    45211 non-null  category\n",
      " 9   duration   45211 non-null  int64   \n",
      " 10  campaign   45211 non-null  int64   \n",
      " 11  pdays      45211 non-null  int64   \n",
      " 12  previous   45211 non-null  int64   \n",
      " 13  poutcome   45211 non-null  category\n",
      " 14  feature    45211 non-null  int64   \n",
      "dtypes: category(8), int64(7)\n",
      "memory usage: 2.8 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Identify categorical features and set their type to 'category'\n",
    "# This allows LightGBM to handle them natively and efficiently\n",
    "categorical_features = dfo.select_dtypes(include=['object']).columns\n",
    "for col in categorical_features:\n",
    "    dfo[col] = dfo[col].astype('category')\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "\n",
    "\n",
    "X = dfo\n",
    "\n",
    "\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f55547fa-46df-45a2-b2b2-73f9d91ef300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-03 17:43:40,785] A new study created in memory with name: no-name-0a717886-c60b-49af-b79b-70957375c5f4\n",
      "[W 2025-08-03 17:44:55,700] Trial 0 failed with parameters: {'learning_rate': 0.009624850513167072, 'num_leaves': 205, 'max_depth': 4, 'min_child_samples': 81, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 1.2517762188242366e-07, 'reg_lambda': 0.6296537388285945} because of the following error: KeyError('train auc-mean').\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\basde\\AppData\\Local\\Temp\\ipykernel_17524\\987721832.py\", line 35, in objective\n",
      "    train_score = cv_results['train auc-mean'][-1]\n",
      "                  ~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'train auc-mean'\n",
      "[W 2025-08-03 17:44:55,704] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'train auc-mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m## 3. Run Tuning Study and Display Results\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# -----------------------------------------\u001b[39;00m\n\u001b[32m     51\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Use a smaller number like 10-15 for a quick test\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Get results as a DataFrame\u001b[39;00m\n\u001b[32m     55\u001b[39m results_df = study.trials_dataframe()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Extract scores from the best iteration\u001b[39;00m\n\u001b[32m     34\u001b[39m cv_score = cv_results[\u001b[33m'\u001b[39m\u001b[33mvalid auc-mean\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m train_score = \u001b[43mcv_results\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain auc-mean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m[-\u001b[32m1\u001b[39m]\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Calculate generalization ratio to check for overfitting\u001b[39;00m\n\u001b[32m     38\u001b[39m generalization_ratio = train_score / cv_score \u001b[38;5;28;01mif\u001b[39;00m cv_score > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'train auc-mean'"
     ]
    }
   ],
   "source": [
    "# 2. Optuna Objective Function with Cross-Validation\n",
    "# ----------------------------------------------------\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Defines the objective function for Optuna to optimize using CV.\"\"\"\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.2, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0, step=0.05),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0, step=0.05),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "    }\n",
    "    \n",
    "    dtrain = lgb.Dataset(X, label=y, categorical_feature=list(categorical_features), free_raw_data=False)\n",
    "    \n",
    "    cv_results = lgb.cv(\n",
    "        params=params,\n",
    "        train_set=dtrain,\n",
    "        num_boost_round=2000,\n",
    "        nfold=5,\n",
    "        stratified=True,\n",
    "        seed=42,\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]\n",
    "    )\n",
    "    \n",
    "    # Extract scores from the best iteration\n",
    "    cv_score = cv_results['valid auc-mean'][-1]\n",
    "    train_score = cv_results['train auc-mean'][-1]\n",
    "    \n",
    "    # Calculate generalization ratio to check for overfitting\n",
    "    generalization_ratio = train_score / cv_score if cv_score > 0 else float('inf')\n",
    "    \n",
    "    # Store extra information in the trial\n",
    "    trial.set_user_attr('train_auc', train_score)\n",
    "    trial.set_user_attr('generalization_ratio', generalization_ratio)\n",
    "    trial.set_user_attr('n_estimators', len(cv_results['valid auc-mean']))\n",
    "    \n",
    "    return cv_score\n",
    "\n",
    "\n",
    "## 3. Run Tuning Study and Display Results\n",
    "# -----------------------------------------\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50) # Use a smaller number like 10-15 for a quick test\n",
    "\n",
    "# Get results as a DataFrame\n",
    "results_df = study.trials_dataframe()\n",
    "\n",
    "# Clean up and select columns for the report\n",
    "results_df = results_df.rename(columns={\n",
    "    'value': 'cv_score',\n",
    "    'user_attrs_train_auc': 'train_score',\n",
    "    'user_attrs_generalization_ratio': 'generalization_ratio',\n",
    "    'user_attrs_n_estimators': 'n_estimators'\n",
    "})\n",
    "results_df['params_learning_rate'] = results_df['params_learning_rate'].round(4)\n",
    "results_df['cv_score'] = results_df['cv_score'].round(5)\n",
    "results_df['train_score'] = results_df['train_score'].round(5)\n",
    "results_df['generalization_ratio'] = results_df['generalization_ratio'].round(4)\n",
    "\n",
    "\n",
    "param_cols = [col for col in results_df.columns if col.startswith('params_')]\n",
    "display_cols = ['cv_score', 'train_score', 'generalization_ratio', 'n_estimators'] + param_cols\n",
    "\n",
    "# Sort by the best CV score and display the top trials\n",
    "print(\"\\n--- Hyperparameter Tuning Results Summary ---\")\n",
    "print(results_df[display_cols].sort_values(by='cv_score', ascending=False).head(10))\n",
    "\n",
    "\n",
    "## 4. Review Best Trial and Train Final Model\n",
    "# ---------------------------------------------\n",
    "print(\"\\n--- Best Trial Details ---\")\n",
    "best_trial = study.best_trial\n",
    "print(f\"Best CV Score: {best_trial.value:.5f}\")\n",
    "print(\"Best Parameters:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(f\"  n_estimators: {best_trial.user_attrs['n_estimators']}\")\n",
    "\n",
    "print(\"\\nTraining final model with best parameters...\")\n",
    "best_params = best_trial.params\n",
    "best_params['n_estimators'] = best_trial.user_attrs['n_estimators']\n",
    "\n",
    "final_model = lgb.LGBMClassifier(**best_params)\n",
    "final_model.fit(X, y, categorical_feature=list(categorical_features))\n",
    "print(\"Final model trained and ready. ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c20a3a-82dc-4698-a6cf-8611d441603d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
