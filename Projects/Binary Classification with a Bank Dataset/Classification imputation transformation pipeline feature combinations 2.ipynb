{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a83ca33-c4af-44d0-bfc1-2e77018dc26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4778aecf-73cb-4404-8cdc-01041192801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classification dataset\n",
    "dft = pd.read_csv(r\"C:\\Users\\basde\\Documents\\GitHub\\Code-and-examples\\Projects\\Binary Classification with a Bank Dataset\\train.csv\")\n",
    "dfo = pd.read_csv(r\"C:\\Users\\basde\\Documents\\GitHub\\Code-and-examples\\Projects\\Binary Classification with a Bank Dataset\\bank-full.csv\", delimiter=';')\n",
    "dfo['y'] = dfo['y'].map({'no' : 0, 'yes': 1})\n",
    "# df = pd.concat([dft, dfo])\n",
    "y = dfo['y']\n",
    "dfo = dfo.drop('y', axis=1)\n",
    "dfo = dfo.drop(['job','marital'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80419a82-90ce-450f-ab82-5505c7767502",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo['default'] = pd.get_dummies(dfo['default'], drop_first=True, dtype=int)\n",
    "dfo['housing'] = pd.get_dummies(dfo['housing'], drop_first=True, dtype=int)\n",
    "dfo['loan'] = pd.get_dummies(dfo['loan'], drop_first=True, dtype=int)\n",
    "dfo['poutcome'] = dfo['poutcome'].map({'failure': '0', 'other' : '0', 'unknown' : '0', 'succes' : '1'})\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "category_order = ['primary', 'secondary', 'unknown', 'tertiary']\n",
    "ordinal_encoder = OrdinalEncoder(categories=[category_order])\n",
    "dfo['education'] = ordinal_encoder.fit_transform(dfo[['education']])\n",
    "dfo['contact'] = dfo['contact'].map({'telephone': 'cellular', 'unknown' : 'unknown', 'telephone': 'telephone'})\n",
    "dfo['contact'] = pd.get_dummies(dfo['contact'], drop_first=True, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32a57e6f-9253-45da-9061-3aff95b21f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   age        45211 non-null  int64   \n",
      " 1   education  45211 non-null  float64 \n",
      " 2   default    45211 non-null  int64   \n",
      " 3   balance    45211 non-null  int64   \n",
      " 4   housing    45211 non-null  int64   \n",
      " 5   loan       45211 non-null  int64   \n",
      " 6   contact    45211 non-null  int64   \n",
      " 7   day        45211 non-null  int64   \n",
      " 8   month      45211 non-null  category\n",
      " 9   duration   45211 non-null  int64   \n",
      " 10  campaign   45211 non-null  int64   \n",
      " 11  pdays      45211 non-null  int64   \n",
      " 12  previous   45211 non-null  int64   \n",
      " 13  poutcome   43700 non-null  category\n",
      "dtypes: category(2), float64(1), int64(11)\n",
      "memory usage: 4.2 MB\n"
     ]
    }
   ],
   "source": [
    "X = dfo.copy()\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47e7ea25-3472-404f-9260-4fac16f053fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MultiInteractionFeatureAdder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A custom transformer that adds new features by multiplying existing ones.\n",
    "    \"\"\"\n",
    "    def __init__(self, interactions_to_add):\n",
    "        self.interactions_to_add = interactions_to_add\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise TypeError(\"MultiInteractionFeatureAdder requires a pandas DataFrame as input.\")\n",
    "        \n",
    "        X_copy = X.copy()\n",
    "        for interaction_tuple in self.interactions_to_add:\n",
    "            new_col_name = '_x_'.join(interaction_tuple)\n",
    "            X_copy[new_col_name] = X_copy[list(interaction_tuple)].prod(axis=1)\n",
    "        return X_copy\n",
    "\n",
    "class ColumnDropper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A custom transformer that drops specified columns from a DataFrame.\n",
    "    \"\"\"\n",
    "    def __init__(self, cols_to_drop):\n",
    "        self.cols_to_drop = cols_to_drop\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise TypeError(\"ColumnDropper requires a pandas DataFrame as input.\")\n",
    "        return X.drop(columns=self.cols_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35a7db8c-5858-4942-9977-c8982f8c46e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "\n",
    "# a. Define the classification models to evaluate\n",
    "models = {\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# b. !!! ACTION REQUIRED !!!\n",
    "# Fill this list with the best interaction terms you found in the last experiment.\n",
    "# The format is a list of tuples.\n",
    "shortlist_of_interactions = [\n",
    "    ('duration', 'campaign', 'pdays')\n",
    "]\n",
    "# c. Define all transformation pipelines\n",
    "# c. Initialize pipelines and add the baseline model for comparison\n",
    "transformation_pipelines = {}\n",
    "transformation_pipelines['Baseline_Original_Features'] = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# d. Create pipelines for all combinations of the shortlisted features\n",
    "# This will test the features individually (r=1) and in combination (r>1).\n",
    "for r in range(1, len(shortlist_of_interactions) + 1):\n",
    "    for subset in itertools.combinations(shortlist_of_interactions, r):\n",
    "        # Create a descriptive name from the feature names in the subset\n",
    "        name = ' & '.join(['_x_'.join(i) for i in subset])\n",
    "        pipeline_name = f'Originals_Plus_{name}'\n",
    "        \n",
    "        # Create a pipeline that adds all interactions in the current subset\n",
    "        pipe = Pipeline([\n",
    "            ('add_interactions', MultiInteractionFeatureAdder(interactions_to_add=list(subset))),\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        transformation_pipelines[pipeline_name] = pipe\n",
    "\n",
    "# e. Define scoring and cross-validation\n",
    "scoring_metrics = { 'f1_score': 'f1_weighted', 'accuracy': 'accuracy' }\n",
    "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c293cf4-e09f-4180-b5a0-cd919777ce60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating Model: LightGBM ---\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 655, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 589, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 719, in fit_transform\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 589, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 897, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\impute\\_base.py\", line 436, in fit\n    X = self._validate_input(X, in_fit=True)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\impute\\_base.py\", line 361, in _validate_input\n    raise new_ve from None\nValueError: Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'may'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tech_name, preprocessor \u001b[38;5;129;01min\u001b[39;00m transformation_pipelines.items():\n\u001b[32m     13\u001b[39m     full_pipeline = Pipeline(steps=[\n\u001b[32m     14\u001b[39m         (\u001b[33m'\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m'\u001b[39m, preprocessor),\n\u001b[32m     15\u001b[39m         (\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m, model)\n\u001b[32m     16\u001b[39m     ])\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     scores = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfull_pipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscoring_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     model_results[tech_name] = {\n\u001b[32m     22\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mTrain F1-Score\u001b[39m\u001b[33m'\u001b[39m: scores[\u001b[33m'\u001b[39m\u001b[33mtrain_f1_score\u001b[39m\u001b[33m'\u001b[39m].mean(),\n\u001b[32m     23\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mCV F1-Score\u001b[39m\u001b[33m'\u001b[39m: scores[\u001b[33m'\u001b[39m\u001b[33mtest_f1_score\u001b[39m\u001b[33m'\u001b[39m].mean(),\n\u001b[32m     24\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mCV Accuracy\u001b[39m\u001b[33m'\u001b[39m: scores[\u001b[33m'\u001b[39m\u001b[33mtest_accuracy\u001b[39m\u001b[33m'\u001b[39m].mean()\n\u001b[32m     25\u001b[39m     }\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- tranformation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtech_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:419\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    398\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m    399\u001b[39m results = parallel(\n\u001b[32m    400\u001b[39m     delayed(_fit_and_score)(\n\u001b[32m    401\u001b[39m         clone(estimator),\n\u001b[32m   (...)\u001b[39m\u001b[32m    416\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[32m    417\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:505\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    499\u001b[39m     all_fits_failed_message = (\n\u001b[32m    500\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    503\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    508\u001b[39m     some_fits_failed_message = (\n\u001b[32m    509\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    510\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    514\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 655, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 589, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 719, in fit_transform\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 589, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 897, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\impute\\_base.py\", line 436, in fit\n    X = self._validate_input(X, in_fit=True)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\basde\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\impute\\_base.py\", line 361, in _validate_input\n    raise new_ve from None\nValueError: Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'may'\n"
     ]
    }
   ],
   "source": [
    "# This DataFrame will hold all results for final comparison\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "# --- Main Loop ---\n",
    "for model_name, model in models.items():\n",
    "    print(f\"--- Evaluating Model: {model_name} ---\")\n",
    "    model_results = {}\n",
    "\n",
    "\n",
    "    # c. Transformation Pipelines Evaluation\n",
    "    # Iterates through the ColumnTransformer pipelines defined in cell 3\n",
    "    for tech_name, preprocessor in transformation_pipelines.items():\n",
    "        full_pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        scores = cross_validate(\n",
    "            full_pipeline, X, y, cv=cv_strategy,\n",
    "            scoring=scoring_metrics, return_train_score=True\n",
    "        )\n",
    "        model_results[tech_name] = {\n",
    "            'Train F1-Score': scores['train_f1_score'].mean(),\n",
    "            'CV F1-Score': scores['test_f1_score'].mean(),\n",
    "            'CV Accuracy': scores['test_accuracy'].mean()\n",
    "        }\n",
    "        print(f\"--- tranformation: {tech_name} ---\")\n",
    "    # d. Consolidate and store results\n",
    "    temp_df = pd.DataFrame.from_dict(model_results, orient='index')\n",
    "    temp_df['Model'] = model_name\n",
    "    all_results = pd.concat([all_results, temp_df])\n",
    "\n",
    "# e. Final processing for the results table\n",
    "all_results.reset_index(inplace=True)\n",
    "all_results.rename(columns={'index': 'Preprocessing Technique'}, inplace=True)\n",
    "all_results['Generalization'] = all_results['CV F1-Score'] / all_results['Train F1-Score']\n",
    "all_results = all_results.sort_values(by='CV F1-Score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488e7202-c308-46ad-8035-3a282447c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns for a more logical presentation\n",
    "final_columns_order = [\n",
    "    'Model',\n",
    "    'Preprocessing Technique',\n",
    "    'CV F1-Score',\n",
    "    'CV Accuracy',\n",
    "    'Train F1-Score',\n",
    "    'Generalization'\n",
    "]\n",
    "all_results = pd.DataFrame(all_results[final_columns_order])\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "all_results.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be208fa-ad43-40a2-9f48-6a245707584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LightGBM\tOriginals_Plus_duration_x_campaign_x_pdays\t0.890248\t0.899892\t0.910073\t0.978216\n",
    "13\tLightGBM\tOriginals_Plus_duration_x_campaign_x_pdays & balance_x_age & duration_x_pdays_x_balance\t0.889545\t0.899228\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d64ad5-2697-4016-b5df-cffd25a7ab08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
