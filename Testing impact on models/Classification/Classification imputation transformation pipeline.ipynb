{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a83ca33-c4af-44d0-bfc1-2e77018dc26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4778aecf-73cb-4404-8cdc-01041192801f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'Age': 177\n"
     ]
    }
   ],
   "source": [
    "# Load the classification dataset\n",
    "train = pd.read_csv(r\"C:\\Users\\basde\\OneDrive\\Documenten\\GitHub\\Titanic\\train.csv\")\n",
    "\n",
    "# Create feature matrix (X) and target vector (y)\n",
    "X = train.select_dtypes(include=np.number).drop(['Survived', 'PassengerId'], axis=1)\n",
    "y = train['Survived']\n",
    "\n",
    "print(f\"Missing values in 'Age': {X['Age'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29e4e136-5974-4ba6-985c-335623f2133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Define the classification models to evaluate\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# b. Define the transformation pipelines to test\n",
    "transformation_pipelines = {\n",
    "    'Standard Scaler': Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]),\n",
    "    'MinMax Scaler': Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', MinMaxScaler())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# c. Define the classification scoring metrics\n",
    "scoring_metrics = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1_score': 'f1_weighted',\n",
    "    'precision': 'precision_weighted',\n",
    "    'recall': 'recall_weighted'\n",
    "}\n",
    "\n",
    "# d. Define the cross-validation strategy\n",
    "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c293cf4-e09f-4180-b5a0-cd919777ce60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating Model: Logistic Regression ---\n",
      "--- Evaluating Model: Random Forest ---\n"
     ]
    }
   ],
   "source": [
    "# This DataFrame will hold all results for final comparison\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "# --- Main Loop ---\n",
    "for model_name, model in models.items():\n",
    "    print(f\"--- Evaluating Model: {model_name} ---\")\n",
    "    model_results = {}\n",
    "\n",
    "    # a. \"Feature Dropped\" Evaluation\n",
    "    X_dropped = X.drop(columns=['Age'])\n",
    "    feature_dropped_scores = cross_validate(\n",
    "        model, X_dropped, y, cv=cv_strategy,\n",
    "        scoring=scoring_metrics, return_train_score=True\n",
    "    )\n",
    "    model_results['Feature Dropped'] = {\n",
    "        'Train F1-Score': feature_dropped_scores['train_f1_score'].mean(),\n",
    "        'CV F1-Score': feature_dropped_scores['test_f1_score'].mean(),\n",
    "        'CV Accuracy': feature_dropped_scores['test_accuracy'].mean()\n",
    "    }\n",
    "\n",
    "    # b. \"Imputation Only\" Baseline Evaluation\n",
    "    baseline_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    baseline_scores = cross_validate(\n",
    "        baseline_pipeline, X, y, cv=cv_strategy,\n",
    "        scoring=scoring_metrics, return_train_score=True\n",
    "    )\n",
    "    model_results['Baseline (Imputation Only)'] = {\n",
    "        'Train F1-Score': baseline_scores['train_f1_score'].mean(),\n",
    "        'CV F1-Score': baseline_scores['test_f1_score'].mean(),\n",
    "        'CV Accuracy': baseline_scores['test_accuracy'].mean()\n",
    "    }\n",
    "\n",
    "    # c. Transformation Pipelines Evaluation\n",
    "    for tech_name, preprocessor in transformation_pipelines.items():\n",
    "        full_pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        scores = cross_validate(\n",
    "            full_pipeline, X, y, cv=cv_strategy,\n",
    "            scoring=scoring_metrics, return_train_score=True\n",
    "        )\n",
    "        model_results[tech_name] = {\n",
    "            'Train F1-Score': scores['train_f1_score'].mean(),\n",
    "            'CV F1-Score': scores['test_f1_score'].mean(),\n",
    "            'CV Accuracy': scores['test_accuracy'].mean()\n",
    "        }\n",
    "\n",
    "    # d. Consolidate and store results\n",
    "    temp_df = pd.DataFrame.from_dict(model_results, orient='index')\n",
    "    temp_df['Model'] = model_name\n",
    "    all_results = pd.concat([all_results, temp_df])\n",
    "\n",
    "# e. Final processing for the results table\n",
    "all_results.reset_index(inplace=True)\n",
    "all_results.rename(columns={'index': 'Preprocessing Technique'}, inplace=True)\n",
    "all_results['Generalization'] = all_results['CV F1-Score'] / all_results['Train F1-Score']\n",
    "all_results = all_results.sort_values(by='CV F1-Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "488e7202-c308-46ad-8035-3a282447c830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing Technique</th>\n",
       "      <th>CV F1-Score</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>Train F1-Score</th>\n",
       "      <th>Generalization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>0.690915</td>\n",
       "      <td>0.707024</td>\n",
       "      <td>0.692252</td>\n",
       "      <td>0.998068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>0.682298</td>\n",
       "      <td>0.684590</td>\n",
       "      <td>0.960595</td>\n",
       "      <td>0.710286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>0.680763</td>\n",
       "      <td>0.698054</td>\n",
       "      <td>0.686705</td>\n",
       "      <td>0.991347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Baseline (Imputation Only)</td>\n",
       "      <td>0.679824</td>\n",
       "      <td>0.682336</td>\n",
       "      <td>0.960595</td>\n",
       "      <td>0.707711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Baseline (Imputation Only)</td>\n",
       "      <td>0.679347</td>\n",
       "      <td>0.696931</td>\n",
       "      <td>0.687389</td>\n",
       "      <td>0.988300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>0.676400</td>\n",
       "      <td>0.678978</td>\n",
       "      <td>0.960595</td>\n",
       "      <td>0.704147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Feature Dropped</td>\n",
       "      <td>0.673472</td>\n",
       "      <td>0.678991</td>\n",
       "      <td>0.845420</td>\n",
       "      <td>0.796613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Feature Dropped</td>\n",
       "      <td>0.672074</td>\n",
       "      <td>0.686837</td>\n",
       "      <td>0.671734</td>\n",
       "      <td>1.000506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model     Preprocessing Technique  CV F1-Score  CV Accuracy  \\\n",
       "3  Logistic Regression               MinMax Scaler     0.690915     0.707024   \n",
       "7        Random Forest               MinMax Scaler     0.682298     0.684590   \n",
       "2  Logistic Regression             Standard Scaler     0.680763     0.698054   \n",
       "5        Random Forest  Baseline (Imputation Only)     0.679824     0.682336   \n",
       "1  Logistic Regression  Baseline (Imputation Only)     0.679347     0.696931   \n",
       "6        Random Forest             Standard Scaler     0.676400     0.678978   \n",
       "4        Random Forest             Feature Dropped     0.673472     0.678991   \n",
       "0  Logistic Regression             Feature Dropped     0.672074     0.686837   \n",
       "\n",
       "   Train F1-Score  Generalization  \n",
       "3        0.692252        0.998068  \n",
       "7        0.960595        0.710286  \n",
       "2        0.686705        0.991347  \n",
       "5        0.960595        0.707711  \n",
       "1        0.687389        0.988300  \n",
       "6        0.960595        0.704147  \n",
       "4        0.845420        0.796613  \n",
       "0        0.671734        1.000506  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorder columns for a more logical presentation\n",
    "final_columns_order = [\n",
    "    'Model',\n",
    "    'Preprocessing Technique',\n",
    "    'CV F1-Score',\n",
    "    'CV Accuracy',\n",
    "    'Train F1-Score',\n",
    "    'Generalization'\n",
    "]\n",
    "all_results = all_results[final_columns_order]\n",
    "\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be208fa-ad43-40a2-9f48-6a245707584d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
