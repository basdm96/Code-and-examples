{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a83ca33-c4af-44d0-bfc1-2e77018dc26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4778aecf-73cb-4404-8cdc-01041192801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classification dataset\n",
    "dft = pd.read_csv(r\"C:\\Users\\basde\\Documents\\GitHub\\Code-and-examples\\Projects\\Binary Classification with a Bank Dataset\\train.csv\")\n",
    "dfo = pd.read_csv(r\"C:\\Users\\basde\\Documents\\GitHub\\Code-and-examples\\Projects\\Binary Classification with a Bank Dataset\\bank-full.csv\", delimiter=';')\n",
    "dfo['y'] = dfo['y'].map({'no' : 0, 'yes': 1})\n",
    "# df = pd.concat([dft, dfo])\n",
    "y = dfo['y']\n",
    "dfo = dfo.drop('y', axis=1)\n",
    "dfo = dfo.drop(['month', 'day', 'job','marital'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80419a82-90ce-450f-ab82-5505c7767502",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo['default'] = pd.get_dummies(dfo['default'], drop_first=True, dtype=int)\n",
    "dfo['housing'] = pd.get_dummies(dfo['housing'], drop_first=True, dtype=int)\n",
    "dfo['loan'] = pd.get_dummies(dfo['loan'], drop_first=True, dtype=int)\n",
    "dfo['poutcome'] = dfo['poutcome'].map({'failure': '0', 'other' : '0', 'unknown' : '0', 'succes' : '1'})\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "category_order = ['primary', 'secondary', 'unknown', 'tertiary']\n",
    "ordinal_encoder = OrdinalEncoder(categories=[category_order])\n",
    "dfo['education'] = ordinal_encoder.fit_transform(dfo[['education']])\n",
    "dfo['contact'] = dfo['contact'].map({'telephone': 'cellular', 'unknown' : 'unknown', 'telephone': 'telephone'})\n",
    "dfo['contact'] = pd.get_dummies(dfo['contact'], drop_first=True, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32a57e6f-9253-45da-9061-3aff95b21f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'education', 'default', 'balance', 'housing', 'loan', 'contact',\n",
       "       'duration', 'campaign', 'pdays', 'previous', 'poutcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dfo.copy()\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47e7ea25-3472-404f-9260-4fac16f053fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MultiInteractionFeatureAdder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A custom transformer that adds new features by multiplying existing ones.\n",
    "    \"\"\"\n",
    "    def __init__(self, interactions_to_add):\n",
    "        self.interactions_to_add = interactions_to_add\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise TypeError(\"MultiInteractionFeatureAdder requires a pandas DataFrame as input.\")\n",
    "        \n",
    "        X_copy = X.copy()\n",
    "        for interaction_tuple in self.interactions_to_add:\n",
    "            new_col_name = '_x_'.join(interaction_tuple)\n",
    "            X_copy[new_col_name] = X_copy[list(interaction_tuple)].prod(axis=1)\n",
    "        return X_copy\n",
    "\n",
    "class ColumnDropper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A custom transformer that drops specified columns from a DataFrame.\n",
    "    \"\"\"\n",
    "    def __init__(self, cols_to_drop):\n",
    "        self.cols_to_drop = cols_to_drop\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise TypeError(\"ColumnDropper requires a pandas DataFrame as input.\")\n",
    "        return X.drop(columns=self.cols_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35a7db8c-5858-4942-9977-c8982f8c46e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "\n",
    "# a. Define the classification models to evaluate\n",
    "models = {\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# b. !!! ACTION REQUIRED !!!\n",
    "# Fill this list with the best interaction terms you found in the last experiment.\n",
    "# The format is a list of tuples.\n",
    "shortlist_of_interactions = [\n",
    "    ('duration', 'campaign', 'pdays'),            \n",
    "    ('duration', 'previous'),                    \n",
    "    ('campaign', 'pdays', 'previous'),   \n",
    "    ('campaign', 'pdays')  \n",
    "]\n",
    "# c. Define all transformation pipelines\n",
    "# c. Initialize pipelines and add the baseline model for comparison\n",
    "transformation_pipelines = {}\n",
    "transformation_pipelines['Baseline_Original_Features'] = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# d. Create pipelines for all combinations of the shortlisted features\n",
    "# This will test the features individually (r=1) and in combination (r>1).\n",
    "for r in range(1, len(shortlist_of_interactions) + 1):\n",
    "    for subset in itertools.combinations(shortlist_of_interactions, r):\n",
    "        # Create a descriptive name from the feature names in the subset\n",
    "        name = ' & '.join(['_x_'.join(i) for i in subset])\n",
    "        pipeline_name = f'Originals_Plus_{name}'\n",
    "        \n",
    "        # Create a pipeline that adds all interactions in the current subset\n",
    "        pipe = Pipeline([\n",
    "            ('add_interactions', MultiInteractionFeatureAdder(interactions_to_add=list(subset))),\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        transformation_pipelines[pipeline_name] = pipe\n",
    "\n",
    "# e. Define scoring and cross-validation\n",
    "scoring_metrics = { 'f1_score': 'f1_weighted', 'accuracy': 'accuracy' }\n",
    "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c293cf4-e09f-4180-b5a0-cd919777ce60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating Model: LightGBM ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 931\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 932\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- tranformation: Baseline_Original_Features ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1186\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1187\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1185\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1185\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1187\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- tranformation: Originals_Plus_duration_x_campaign_x_pdays ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1186\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1187\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1185\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1185\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1187\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- tranformation: Originals_Plus_duration_x_previous ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1186\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1187\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1185\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1185\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1187\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- tranformation: Originals_Plus_campaign_x_pdays_x_previous ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1186\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007000 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1187\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1185\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1185\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1187\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- tranformation: Originals_Plus_campaign_x_pdays ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1441\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1442\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1440\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1440\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1442\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- tranformation: Originals_Plus_duration_x_campaign_x_pdays & duration_x_previous ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1441\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1442\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1440\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1440\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1442\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- tranformation: Originals_Plus_duration_x_campaign_x_pdays & campaign_x_pdays_x_previous ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1441\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1442\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1440\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1440\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1442\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- tranformation: Originals_Plus_duration_x_campaign_x_pdays & campaign_x_pdays ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1441\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1442\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1440\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1440\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1442\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- tranformation: Originals_Plus_duration_x_previous & campaign_x_pdays_x_previous ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1441\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1442\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1440\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1440\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1442\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- tranformation: Originals_Plus_duration_x_previous & campaign_x_pdays ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1441\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1442\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1440\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1440\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1442\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- tranformation: Originals_Plus_campaign_x_pdays_x_previous & campaign_x_pdays ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1696\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1697\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1695\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1695\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1697\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- tranformation: Originals_Plus_duration_x_campaign_x_pdays & duration_x_previous & campaign_x_pdays_x_previous ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1696\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1697\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1695\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1695\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1697\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- tranformation: Originals_Plus_duration_x_campaign_x_pdays & duration_x_previous & campaign_x_pdays ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1696\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1697\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1695\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1695\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1697\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- tranformation: Originals_Plus_duration_x_campaign_x_pdays & campaign_x_pdays_x_previous & campaign_x_pdays ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1696\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1697\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1695\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1695\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1697\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- tranformation: Originals_Plus_duration_x_previous & campaign_x_pdays_x_previous & campaign_x_pdays ---\n",
      "[LightGBM] [Info] Number of positive: 4198, number of negative: 31970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1951\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116069 -> initscore=-2.030190\n",
      "[LightGBM] [Info] Start training from score -2.030190\n",
      "[LightGBM] [Info] Number of positive: 4279, number of negative: 31890\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1952\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118306 -> initscore=-2.008573\n",
      "[LightGBM] [Info] Start training from score -2.008573\n",
      "[LightGBM] [Info] Number of positive: 4184, number of negative: 31985\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1950\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.115679 -> initscore=-2.033999\n",
      "[LightGBM] [Info] Start training from score -2.033999\n",
      "[LightGBM] [Info] Number of positive: 4269, number of negative: 31900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1950\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118029 -> initscore=-2.011226\n",
      "[LightGBM] [Info] Start training from score -2.011226\n",
      "[LightGBM] [Info] Number of positive: 4226, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1952\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116840 -> initscore=-2.022697\n",
      "[LightGBM] [Info] Start training from score -2.022697\n",
      "--- tranformation: Originals_Plus_duration_x_campaign_x_pdays & duration_x_previous & campaign_x_pdays_x_previous & campaign_x_pdays ---\n"
     ]
    }
   ],
   "source": [
    "# This DataFrame will hold all results for final comparison\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "# --- Main Loop ---\n",
    "for model_name, model in models.items():\n",
    "    print(f\"--- Evaluating Model: {model_name} ---\")\n",
    "    model_results = {}\n",
    "\n",
    "\n",
    "    # c. Transformation Pipelines Evaluation\n",
    "    # Iterates through the ColumnTransformer pipelines defined in cell 3\n",
    "    for tech_name, preprocessor in transformation_pipelines.items():\n",
    "        full_pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        scores = cross_validate(\n",
    "            full_pipeline, X, y, cv=cv_strategy,\n",
    "            scoring=scoring_metrics, return_train_score=True\n",
    "        )\n",
    "        model_results[tech_name] = {\n",
    "            'Train F1-Score': scores['train_f1_score'].mean(),\n",
    "            'CV F1-Score': scores['test_f1_score'].mean(),\n",
    "            'CV Accuracy': scores['test_accuracy'].mean()\n",
    "        }\n",
    "        print(f\"--- tranformation: {tech_name} ---\")\n",
    "    # d. Consolidate and store results\n",
    "    temp_df = pd.DataFrame.from_dict(model_results, orient='index')\n",
    "    temp_df['Model'] = model_name\n",
    "    all_results = pd.concat([all_results, temp_df])\n",
    "\n",
    "# e. Final processing for the results table\n",
    "all_results.reset_index(inplace=True)\n",
    "all_results.rename(columns={'index': 'Preprocessing Technique'}, inplace=True)\n",
    "all_results['Generalization'] = all_results['CV F1-Score'] / all_results['Train F1-Score']\n",
    "all_results = all_results.sort_values(by='CV F1-Score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "488e7202-c308-46ad-8035-3a282447c830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Preprocessing Technique</th>\n",
       "      <th>CV F1-Score</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>Train F1-Score</th>\n",
       "      <th>Generalization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Originals_Plus_duration_x_campaign_x_pdays</td>\n",
       "      <td>0.890248</td>\n",
       "      <td>0.899892</td>\n",
       "      <td>0.910073</td>\n",
       "      <td>0.978216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Originals_Plus_duration_x_campaign_x_pdays &amp; c...</td>\n",
       "      <td>0.890058</td>\n",
       "      <td>0.899825</td>\n",
       "      <td>0.909961</td>\n",
       "      <td>0.978128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Originals_Plus_duration_x_previous &amp; campaign_...</td>\n",
       "      <td>0.889944</td>\n",
       "      <td>0.899781</td>\n",
       "      <td>0.910392</td>\n",
       "      <td>0.977539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Originals_Plus_duration_x_campaign_x_pdays &amp; d...</td>\n",
       "      <td>0.889717</td>\n",
       "      <td>0.899693</td>\n",
       "      <td>0.910920</td>\n",
       "      <td>0.976723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Originals_Plus_duration_x_campaign_x_pdays &amp; c...</td>\n",
       "      <td>0.889587</td>\n",
       "      <td>0.899449</td>\n",
       "      <td>0.910679</td>\n",
       "      <td>0.976839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Originals_Plus_duration_x_previous</td>\n",
       "      <td>0.889474</td>\n",
       "      <td>0.898896</td>\n",
       "      <td>0.910012</td>\n",
       "      <td>0.977431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Originals_Plus_duration_x_campaign_x_pdays &amp; d...</td>\n",
       "      <td>0.889453</td>\n",
       "      <td>0.899449</td>\n",
       "      <td>0.911278</td>\n",
       "      <td>0.976050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Originals_Plus_duration_x_campaign_x_pdays &amp; c...</td>\n",
       "      <td>0.889351</td>\n",
       "      <td>0.899118</td>\n",
       "      <td>0.910527</td>\n",
       "      <td>0.976743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Originals_Plus_campaign_x_pdays_x_previous</td>\n",
       "      <td>0.889326</td>\n",
       "      <td>0.899095</td>\n",
       "      <td>0.909740</td>\n",
       "      <td>0.977560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Originals_Plus_duration_x_campaign_x_pdays &amp; d...</td>\n",
       "      <td>0.889258</td>\n",
       "      <td>0.899272</td>\n",
       "      <td>0.910501</td>\n",
       "      <td>0.976669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Originals_Plus_duration_x_campaign_x_pdays &amp; d...</td>\n",
       "      <td>0.889173</td>\n",
       "      <td>0.899140</td>\n",
       "      <td>0.911569</td>\n",
       "      <td>0.975432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Originals_Plus_campaign_x_pdays</td>\n",
       "      <td>0.888930</td>\n",
       "      <td>0.898808</td>\n",
       "      <td>0.910275</td>\n",
       "      <td>0.976551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Originals_Plus_campaign_x_pdays_x_previous &amp; c...</td>\n",
       "      <td>0.888654</td>\n",
       "      <td>0.898366</td>\n",
       "      <td>0.910307</td>\n",
       "      <td>0.976213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Originals_Plus_duration_x_previous &amp; campaign_...</td>\n",
       "      <td>0.888471</td>\n",
       "      <td>0.898542</td>\n",
       "      <td>0.910577</td>\n",
       "      <td>0.975723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Originals_Plus_duration_x_previous &amp; campaign_...</td>\n",
       "      <td>0.887896</td>\n",
       "      <td>0.897768</td>\n",
       "      <td>0.910473</td>\n",
       "      <td>0.975202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Baseline_Original_Features</td>\n",
       "      <td>0.887892</td>\n",
       "      <td>0.897835</td>\n",
       "      <td>0.909662</td>\n",
       "      <td>0.976067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model                            Preprocessing Technique  CV F1-Score  \\\n",
       "1   LightGBM         Originals_Plus_duration_x_campaign_x_pdays     0.890248   \n",
       "13  LightGBM  Originals_Plus_duration_x_campaign_x_pdays & c...     0.890058   \n",
       "9   LightGBM  Originals_Plus_duration_x_previous & campaign_...     0.889944   \n",
       "12  LightGBM  Originals_Plus_duration_x_campaign_x_pdays & d...     0.889717   \n",
       "7   LightGBM  Originals_Plus_duration_x_campaign_x_pdays & c...     0.889587   \n",
       "2   LightGBM                 Originals_Plus_duration_x_previous     0.889474   \n",
       "11  LightGBM  Originals_Plus_duration_x_campaign_x_pdays & d...     0.889453   \n",
       "6   LightGBM  Originals_Plus_duration_x_campaign_x_pdays & c...     0.889351   \n",
       "3   LightGBM         Originals_Plus_campaign_x_pdays_x_previous     0.889326   \n",
       "5   LightGBM  Originals_Plus_duration_x_campaign_x_pdays & d...     0.889258   \n",
       "15  LightGBM  Originals_Plus_duration_x_campaign_x_pdays & d...     0.889173   \n",
       "4   LightGBM                    Originals_Plus_campaign_x_pdays     0.888930   \n",
       "10  LightGBM  Originals_Plus_campaign_x_pdays_x_previous & c...     0.888654   \n",
       "14  LightGBM  Originals_Plus_duration_x_previous & campaign_...     0.888471   \n",
       "8   LightGBM  Originals_Plus_duration_x_previous & campaign_...     0.887896   \n",
       "0   LightGBM                         Baseline_Original_Features     0.887892   \n",
       "\n",
       "    CV Accuracy  Train F1-Score  Generalization  \n",
       "1      0.899892        0.910073        0.978216  \n",
       "13     0.899825        0.909961        0.978128  \n",
       "9      0.899781        0.910392        0.977539  \n",
       "12     0.899693        0.910920        0.976723  \n",
       "7      0.899449        0.910679        0.976839  \n",
       "2      0.898896        0.910012        0.977431  \n",
       "11     0.899449        0.911278        0.976050  \n",
       "6      0.899118        0.910527        0.976743  \n",
       "3      0.899095        0.909740        0.977560  \n",
       "5      0.899272        0.910501        0.976669  \n",
       "15     0.899140        0.911569        0.975432  \n",
       "4      0.898808        0.910275        0.976551  \n",
       "10     0.898366        0.910307        0.976213  \n",
       "14     0.898542        0.910577        0.975723  \n",
       "8      0.897768        0.910473        0.975202  \n",
       "0      0.897835        0.909662        0.976067  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorder columns for a more logical presentation\n",
    "final_columns_order = [\n",
    "    'Model',\n",
    "    'Preprocessing Technique',\n",
    "    'CV F1-Score',\n",
    "    'CV Accuracy',\n",
    "    'Train F1-Score',\n",
    "    'Generalization'\n",
    "]\n",
    "all_results = all_results[final_columns_order]\n",
    "\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4be208fa-ad43-40a2-9f48-6a245707584d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1450552359.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mLightGBM\tManualMap_OneHotEncoder\t0.893398\t0.902856\t0.912014\t0.979588\u001b[39m\n            \t^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "LightGBM\tManualMap_OneHotEncoder\t0.893398\t0.902856\t0.912014\t0.979588\n",
    "6\tLightGBM\tOrdinalEncoder\t0.893398\t0.902922\t0.912159\t0.979432\n",
    "5\tLightGBM\tOneHotEncoder\t0.892881\t0.902258\t0.912397\t0.978610\n",
    "\n",
    "LightGBM\tOrdinalEncoder\t0.893530\t0.902856\t0.911901\t0.979854\n",
    "7\tLightGBM\tManualMap_OneHotEncoder\t0.893398\t0.902856\t0.912014\t0.979588\n",
    "5\tLightGBM\tOneHotEncoder\t0.892760\t0.902325\t0.912347\t0.978531"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
